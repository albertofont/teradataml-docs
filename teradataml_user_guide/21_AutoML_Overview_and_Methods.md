# AutoML Overview and Methods

Automated Machine Learning (AutoML) represents a method for streamlining the entire process of machine
learning pipeline in automated way. It encompasses various distinct phases of the machine learning pipeline,
including feature exploration, features engineering, data preparation, model selection, model training with
hyperparameters tuning, and model evaluation. By automating these tasks, AutoML eliminates the need
for manual intervention by trained data scientists and reduces the prerequisite knowledge required for
beginners. This accessibility allows individuals of varying expertise levels to effortlessly use AutoML to create
machine learning models in an automated fashion.
The following diagram provides additional insights over AutoML approach.
teradataml AutoML consists of five different phases covering different processes in automated way.
                                        19
* Feature Exploration: It explores available features and provides insights such as column summary,
  categorical features distinct count, outlier percentage details, futile column details, and target
  column distribution.
* Feature Engineering: It handles data anomalies such as duplicate rows handling, missing value
  handling, futile column handling. Additionally, it executes various feature transformations based on the
  data types of the features.
* Data Preparation: It performs various steps to prepare the data for model training, including feature
  selection, feature scaling, and splitting the data into training and validation sets.
* Model Training: It performs hyperparameter tuning with available models.
* Model Evaluation: It assesses various trained models and generates a model leaderboard that includes
  performance metrics, detail on the applied feature selection method, and corresponding rankings for
  each model in ascending order. The model ranked 1 indicates the best-performing model for the
  given dataset.
## Key Features of AutoML
Key features of teradataml AutoML:
* Supports different problem types:
  * Regression
  * Binary Classification
  * Multiclass Classification
* Provides the following models for training based on problem types:
  * GLM
  * SVM
  * Decision Forest
  * XGBoost
  * KNN
* Gives flexibility to select specific models out of available models.
* Performs all five phases in automated way, but can also be customized based on user input.
* Generates model leaderboard and leader for given dataset.
* Provides prediction on validation dataset as well as user passed data using model leader or any other
  model from leaderboard.
* Provides early stopping criteria to stop AutoML training before completion time using three different
  options by defining early stopping timer, early stopping metric threshold, and maximum models to
  be trained.
  The number of models generated will be determined by the following:
  * Default condition: The default number of models generated by AutoML if no early stopping criteria
    are used.
* Early stopping conditions: When early stopping conditions are utilized by the user, the final count
    of models will depend on which of these conditions is satisfied first:
    ▪ The number of models trained within the specified early stopping timer.
    ▪ The number of models trained to achieve the specified early stopping performance
    metric threshold.
    ▪ The number of models specified under the maximum models to be trained.
* Provides three different logging levels to display required contents, higher level provides more
  detailed output.
## Methods of AutoML
To facilitate the key features mentioned in the previous section, teradataml AutoML provides the
following methods:
* _init_(): Create instance for AutoML training.
  Three different APIs are available for instance creation based on problem types:
  * AutoML (AutoML.__init__): Generic AutoML API that can be used to solve all three supported
    problem type.
  * AutoRegressor (AutoRegressor.__init__): Specific AutoML API to solve regression problem type.
  * AutoClassifier (AutoClassifier.__init__): Specific AutoML API to solve classification problem type.
  Note:
    The following methods are common to all these three APIs.
* fit: Fit over given dataset during AutoML training.
* leaderboard: Display model leaderboard containing model rank and corresponding
  performance metrics.
* leader: Display best performing model.
* model_hyperparameters: Get hyperparameters of the model based on rank in leaderboard.
* predict: Generate prediction and performance metrics.
* evaluate: Evaluate on data using model rank in leaderboard to generate performance metrics.
* generate_custom_config: Generate custom config JSON required for customized run.
* get_persisted_tables: List the persisted tables created during execution.
* deploy: Save models to the specified table.
* load: Load models information from the specified table.
* remove_saved_models: Remove the specified table containing saved models.
* visualize: Visualize the teradataml DataFrame.
### AutoML.__init__
AutoML is an approach that automates the process of building, training, and validating machine learning
models. It involves various algorithms to automate various aspects of the machine learning workflow, such
as data preparation, feature engineering, model selection, hyperparameter tuning, and model deployment.
It aims to simplify the process of building machine learning models, by automating some of the more
time-consuming and labor-intensive tasks involved in the process.
AutoML is designed to handle both regression and classification (binary and multiclass) tasks. You can
specify the task type on the provided dataset. By default, AutoML decides the task type.
AutoML by default, trains using all model algorithms applicable for the task type problem.
For example,
* For multiclass classification problem, only three models, "svm", "knn", "decision_forest", "xgboost",
  are available to train, by default. Because "glm" and "svm" does not support multiclass
  classification problem.
* For regression and binary classification problem, all five models, "glm", "svm", "knn",
  "decision_forest", "xgboost", are available to train by default.
AutoML provides functionality to use specific model algorithms for training. You can provide either include
or exclude model.
* For include, only specified models are trained.
* For exclude, all models except specified model are trained.
AutoML also provides an option to customize the processes within feature engineering, data preparation
and model training phases. You can customize the processes by passing the JSON file path in case of
custom run. It also supports early stopping of model training based on stopping metrics and maximum
running time.
Note:
configure.temp_object_type="VT" follows sequential execution.
#### Optional Arguments
task_type
    Specifies the task type for AutoML, whether to apply regression or classification on the
    provided dataset.
    Set this argument to "Default", if you want AutoML to decide the task type automatically.
    Permitted values are "Regression", "Classification", "Default".
    Default value is "Default".
include
    Specifies the model algorithms to be used for model training phase.
    By default, all five models are used for training for regression and binary classification
    problem, while only three models are used for multiclass.
    Permitted values are "glm", "svm", "knn", "decision_forest", "xgboost".
exclude
    Specifies the model algorithms to be excluded from model training phase.
    No model is excluded by default.
    Permitted values are "glm", "svm", "knn", "decision_forest", "xgboost".
verbose
    Specifies the detailed execution steps based on verbose level.
    Permitted values are: *
    Default value is 0.
max_runtime_secs
    Specifies the time limit in seconds for model training.
stopping_metric
    Specifies the stopping metrics for stopping tolerance in model training.
    Note:
      This argument is required if stopping_tolerance is set; otherwise, optional.
    Permitted values are:
    * For task_type "Regression": "R2", "MAE", "MSE", "MSLE", "RMSE", "RMSLE".
    * For task_type "Regression": "R2", "MAE", "MSE", "MSLE", "RMSE", "RMSLE", "MAPE",
      "MPE", "ME", "EV", "MPD" and "MGD".
    * For task_type "Classification": 'MICRO-F1','MACRO-F1', 'MICRO-
      RECALL','MACRO-RECALL', 'MICRO-PRECISION', 'MACRO-PRECISION',
      'WEIGHTED-PRECISION','WEIGHTED-RECALL', 'WEIGHTED-F1', 'ACCURACY'.
max_models
    Specifies the maximum number of models to be trained.
stopping_tolerance
    Specifies the stopping tolerance for stopping metrics in model training.
    Note:
      This argument is required if stopping_metric is set; otherwise, optional.
custom_config_file
    Specifies the path of JSON file in case of custom run.
volatile
    Specifies whether to put the interim results of the functions in a volatile table or not. When set
    to True, results are stored in a volatile table, otherwise not.
    Default value: False
    Types: bool
persist
    Specifies whether to persist the interim results of the functions in a table or not. When set to
    True, results are persisted in a table; otherwise, results are garbage collected at the end of
    the session.
    Default value: False
    Types: bool
seed
    Specifies the random seed for reproducibility.
    Default Value: 42
    Types: int
### AutoRegressor.__init__
AutoRegressor is a special purpose AutoML feature to run regression specific tasks.
Note:
configure.temp_object_type="VT" follows sequential execution.
#### Optional Arguments
include
    Specifies the model algorithms to be used for model training phase.
    By default, all five models are used for training for regression and binary classification
    problem, while only three models are used for multiclass.
    Permitted values are "glm", "svm", "knn", "decision_forest", "xgboost".
exclude
    Specifies the model algorithms to be excluded from model training phase.
    No model is excluded by default.
    Permitted values are "glm", "svm", "knn", "decision_forest", "xgboost".
verbose
    Specifies the detailed execution steps based on verbose level.
    Permitted values are: *
    Default value is 0.
max_runtime_secs
    Specifies the time limit in seconds for model training.
stopping_metric
    Specifies the stopping metrics for stopping tolerance in model training.
    Note:
      This argument is required if stopping_tolerance is set; otherwise, optional.
    Permitted values are:
    * For task_type "Regression": "R2", "MAE", "MSE", "MSLE", "RMSE", "RMSLE".
    * For task_type "Regression": "R2", "MAE", "MSE", "MSLE", "RMSE", "RMSLE", "MAPE",
      "MPE", "ME", "EV", "MPD" and "MGD".
    * For task_type "Classification": 'MICRO-F1','MACRO-F1', 'MICRO-
      RECALL','MACRO-RECALL', 'MICRO-PRECISION', 'MACRO-PRECISION',
      'WEIGHTED-PRECISION','WEIGHTED-RECALL', 'WEIGHTED-F1', 'ACCURACY'.
stopping_tolerance
    Specifies the stopping tolerance for stopping metrics in model training.
    Note:
      This argument is required if stopping_metric is set; otherwise, optional.
max_models
    Specifies the maximum number of models to be trained.
custom_config_file
    Specifies the path of JSON file in case of custom run.
volatile
    Specifies whether to put the interim results of the functions in a volatile table or not. When set
    to True, results are stored in a volatile table, otherwise not.
    Default value: False
    Types: bool
persist
    Specifies whether to persist the interim results of the functions in a table or not. When set to
    True, results are persisted in a table; otherwise, results are garbage collected at the end of
    the session.
    Default value: False
    Types: bool
seed
    Specifies the random seed for reproducibility.
    Default Value: 42
    Types: int
### AutoClassifier.__init__
AutoClassifier is a special purpose AutoML feature to run classification specific tasks.
Note:
configure.temp_object_type="VT" follows sequential execution.
#### Optional Arguments
include
    Specifies the model algorithms to be used for model training phase.
    By default, all five models are used for training for regression and binary classification
    problem, while only three models are used for multiclass.
    Permitted values are "glm", "svm", "knn", "decision_forest", "xgboost".
exclude
    Specifies the model algorithms to be excluded from model training phase.
    No model is excluded by default.
    Permitted values are "glm", "svm", "knn", "decision_forest", "xgboost".
verbose
    Specifies the detailed execution steps based on verbose level.
    Permitted values are: *
    Default value is 0.
max_runtime_secs
    Specifies the time limit in seconds for model training.
stopping_metric
    Specifies the stopping metrics for stopping tolerance in model training.
    Note:
      This argument is required if stopping_tolerance is set; otherwise, optional.
    Permitted values are:
    * For task_type "Regression": "R2", "MAE", "MSE", "MSLE", "RMSE", "RMSLE".
    * For task_type "Classification": 'MICRO-F1','MACRO-F1', 'MICRO-
      RECALL','MACRO-RECALL', 'MICRO-PRECISION', 'MACRO-PRECISION',
      'WEIGHTED-PRECISION','WEIGHTED-RECALL', 'WEIGHTED-F1', 'ACCURACY'.
stopping_tolerance
    Specifies the stopping tolerance for stopping metrics in model training.
    Note:
      This argument is required if stopping_metric is set; otherwise, optional.
max_models
    Specifies the maximum number of models to be trained.
custom_config_file
    Specifies the path of JSON file in case of custom run.
seed
    Specifies the random seed for reproducibility.
    Default Value: 42
    Types: int
### fit
Use the fit() function to trigger the AutoML run. It can handle both regression and classification tasks
depending on the value specified in the task_type argument.
Required Arguments:
* data: Specifies the input teradataml DataFrame.
* target_column: Specifies target column of dataset.
### leaderboard
Use the leaderboard() function to display the leaderboard.
This function does not have arguments. It returns pandas DataFrame with Leaderboard information.
### leader
Use the leader() function to display the best performing model.
This function does not have arguments.
It returns None, but displays the best performing model.
### model_hyperparameters
Use the model_hyperparameters() function to get hyperparameters of the model based on rank
in leaderboard.
Note:
If both the fit() and load() methods are invoked before calling model_hyperparameters(), by default
hyperparameters are retrieved from the fit leaderboard.
To retrieve hyperparameters from the loaded models, set "use_loaded_models" to True in the
model_hyperparameters call. Returns Dictionary containing hyperparameters.
Raises TeradataMlException.
Required argument:
* rank specifies the rank of the model in the leaderboard.
  Default value: 1
  Types: int
Optional argument:
* use_loaded_models specifies the rank of the model in the leaderboard.
  Default value: False
  Types: bool
### predict
Use the predict() function to generate prediction on either default test data or any other data using model
rank in leaderboard and display performance metrics of the specified model.
If test data contains target column, it displays both prediction and performance metrics; otherwise, it
displays only prediction.
Required argument:
* data: Specifies the dataset (teradataml DataFrame) on which prediction needs to be generated using
  model rank in leaderboard.
Optional Arguments:
* rank: Specifies the rank of the model in the leaderboard to be used for prediction.
  Default value is 1.
* data: Specifies the dataset (teradataml DataFrame) on which prediction and performance metrics
  needs to be generated using model rank in leaderboard.
  When this argument is not specified, default test data is used. Default test data is the dataset
  generated at the time of training.
* rank: Specifies the rank of the model in the leaderboard to be used for prediction.
  Default value is 1.
This function returns pandas DataFrame with prediction.
### evaluate
Use the evaluate() function to evaluate on data using model rank in leaderboard and generate performance
metrics. Returns DataFrame with performance metrics.
Raises TeradataMlException.
Note:
If both fit and load methods are called before predict, then fit method model will be used for prediction
by default unless 'use_loaded_models' is set to True in predict.
Required argument:
* data specifies the dataset on which performance metrics needs to be generated.
  Types: teradataml DataFrame
  Note:
    Target column used for generating model is mandatory in data for evaluation.
Optional arguments:
* rank specifies the rank of the model available in the leaderboard to be used for evaluation.
  Default value: 1
  Types: int
* use_loaded_models specifies whether to use loaded models from database for prediction or not.
  Default value: False
  Types: bool
### generate_custom_config
Use the generate_custom_config function to generate custom JSON file containing user customized input
under current working directory which can be used for AutoML execution.
Optional Argument:
* file_name: Specifies the name of the file to be generated.
  Default value is "custom".
Note:
    Do not pass the file name with extension. Extension '.json' is automatically added to specified
    file name.
#### Example Setup
Before generating custom JSON file, import either AutoML, or AutoClassifier, or AutoRegressor, from
teradataml based on the feature you choose.
The following example imports all three.
```python
from teradataml import AutoML, AutoClassifier, AutoRegressor
```
#### Example 1: Generate a default file named "custom.json"
Based on the feature for your use case, generate a default file named "custom.json" file using one of the
following options.
```python
AutoML.generate_custom_config()
```
Or,
```python
AutoClassifier.generate_custom_config()
```
Or,
```python
AutoRegressor.generate_custom_config()
```
#### Example 2: Generate file with different file names using file_name argument
The following code generates JSON file with specified file name under current working directory.
```python
AutoML.generate_custom_config("custom_titanic")
```
Or,
```python
AutoClassifier.generate_custom_config("custom_titanic")
```
Or,
```python
AutoRegressor.generate_custom_config("custom_housing")
```
#### Example system output
The generate_custom_config() method enables the generation of customized JSON by allowing you to
provide appropriate responses to available options. It requires either the index value corresponding to the
given option or the feature name on which customization needs to be done.
You can provide a single value or a list of values, separated by commas, based on the prompt details.
Note:
As AutoML does not have access to features beforehand, it is your responsibility to enter the correct
feature names from the dataset.
```python
AutoRegressor.generate_custom_config("custom_housing")
Generating custom config JSON for AutoML ...
Available main options for customization with corresponding indices:
Index 1: Customize Feature Engineering Phase
Index 2: Customize Data Preparation Phase
Index 3: Customize Model Training Phase
Index 4: Generate custom json and exit
Enter the index you want to customize:  1
Customizing Feature Engineering Phase ...
Available options for customization of feature engineering phase with
corresponding indices:
Index 1: Customize Missing Value Handling
Index 2: Customize Bincode Encoding
Index 3: Customize String Manipulation
Index 4: Customize Categorical Encoding
Index 5: Customize Mathematical Transformation
Index 6: Customize Nonlinear Transformation
Index 7: Customize Antiselect Features
Index 8: Back to main menu
Index 9: Generate custom json and exit
Enter the list of indices you want to customize in feature engineering
phase:  2,4,7,8
Customizing Bincode Encoding ...
Provide the following details to customize binning and coding encoding:
Available binning methods with corresponding indices:
Index 1: Equal-Width
Index 2: Variable-Width
Enter the feature or list of features for binning:  bedrooms
Enter the index of corresponding binning method for feature bedrooms:  2
Enter the number of bins for feature bedrooms:  2
Available value type of feature for variable binning with corresponding indices:
Index 1: int
Index 2: float
Provide the range for bin 1 of feature bedrooms:
Enter the index of corresponding value type of feature bedrooms:  1
Enter the minimum value for bin 1 of feature bedrooms:  0
Enter the maximum value for bin 1 of feature bedrooms:  2
Enter the label for bin 1 of feature bedrooms:  small_house
Provide the range for bin 2 of feature bedrooms:
Enter the index of corresponding value type of feature bedrooms:  1
Enter the minimum value for bin 2 of feature bedrooms:  3
Enter the maximum value for bin 2 of feature bedrooms:  5
Enter the label for bin 2 of feature bedrooms:  big_house
Customization of bincode encoding has been completed successfully.
Customizing Categorical Encoding ...
Provide the following details to customize categorical encoding:
Available categorical encoding methods with corresponding indices:
Index 1: OneHotEncoding
Index 2: OrdinalEncoding
Index 3: TargetEncoding
Enter the list of corresponding index categorical encoding methods you want to
use:  2,3
Enter the feature or list of features for OrdinalEncoding:  homestyle
Enter the feature or list of features for TargetEncoding:  prefarea
Available target encoding methods with corresponding indices:
Index 1: CBM_BETA
Index 2: CBM_DIRICHLET
Index 3: CBM_GAUSSIAN_INVERSE_GAMMA
Enter the index of target encoding method for feature prefarea:  3
Enter the response column for target encoding method for feature
prefarea:  price
Customization of categorical encoding has been completed successfully.
Customizing Antiselect Features ...
Enter the feature or list of features for antiselect:  sn
Customization of antiselect features has been completed successfully.
Customization of feature engineering phase has been completed successfully.
Available main options for customization with corresponding indices:
Index 1: Customize Feature Engineering Phase
Index 2: Customize Data Preparation Phase
Index 3: Customize Model Training Phase
Index 4: Generate custom json and exit
Enter the index you want to customize:  2
Customizing Data Preparation Phase ...
Available options for customization of data preparation phase with
corresponding indices:
Index 1: Customize Train Test Split
Index 2: Customize Data Imbalance Handling
Index 3: Customize Outlier Handling
Index 4: Customize Feature Scaling
Index 5: Back to main menu
Index 6: Generate custom json and exit
Enter the list of indices you want to customize in data preparation
phase:  1,2,3,4,5
Customizing Train Test Split ...
Enter the train size for train test split:  0.75
Customization of train test split has been completed successfully.
Customizing Data Imbalance Handling ...
Available data sampling methods with corresponding indices:
Index 1: SMOTE
Index 2: NearMiss
Enter the corresponding index data imbalance handling method:  1
Customization of data imbalance handling has been completed successfully.
Customizing Outlier Handling ...
Available outlier detection methods with corresponding indices:
Index 1: percentile
Index 2: tukey
Index 3: carling
Enter the corresponding index oulier handling method:  1
Enter the lower percentile value for outlier handling:  0.1
Enter the upper percentile value for outlier handling:  0.9
Enter the feature or list of features for outlier handling:  bathrms
Available outlier replacement methods with corresponding indices:
Index 1: delete
Index 2: median
Index 3: Any Numeric Value
Enter the index of corresponding replacement method for feature bathrms:  1
Customization of outlier handling has been completed successfully.
Available feature scaling methods with corresponding indices:
Index 1: maxabs
Index 2: mean
Index 3: midrange
Index 4: range
Index 5: rescale
Index 6: std
Index 7: sum
Index 8: ustd
Enter the corresponding index feature scaling method:  6
Customization of feature scaling has been completed successfully.
Customization of data preparation phase has been completed successfully.
Available main options for customization with corresponding indices:
Index 1: Customize Feature Engineering Phase
Index 2: Customize Data Preparation Phase
Index 3: Customize Model Training Phase
Index 4: Generate custom json and exit
Enter the index you want to customize:  3
Customizing Model Training Phase ...
Available options for customization of model training phase with
corresponding indices:
Index 1: Customize Model Hyperparameter
Index 2: Back to main menu
Index 3: Generate custom json and exit
Enter the list of indices you want to customize in model training phase:  1
Customizing Model Hyperparameter ...
Available models for hyperparameter tuning with corresponding indices:
Index 1: decision_forest
Index 2: xgboost
Index 3: knn
Index 4: glm
Index 5: svm
Available hyperparamters update methods with corresponding indices:
Index 1: ADD
Index 2: REPLACE
Enter the list of model indices for performing hyperparameter tuning:  2
Available hyperparameters for model 'xgboost' with corresponding indices:
Index 1: min_impurity
Index 2: max_depth
Index 3: min_node_size
Index 4: shrinkage_factor
Index 5: iter_num
Enter the list of hyperparameter indices for model 'xgboost':  3
Enter the index of corresponding update method for hyperparameters
'min_node_size' for model 'xgboost':  1
Enter the list of value for hyperparameter 'min_node_size' for model
'xgboost':  1,2
Customization of model hyperparameter has been completed successfully.
Available options for customization of model training phase with
corresponding indices:
Index 1: Customize Model Hyperparameter
Index 2: Back to main menu
Index 3: Generate custom json and exit
Enter the list of indices you want to customize in model training phase:  2
Customization of model training phase has been completed successfully.
Available main options for customization with corresponding indices:
Index 1: Customize Feature Engineering Phase
Index 2: Customize Data Preparation Phase
Index 3: Customize Model Training Phase
Index 4: Generate custom json and exit
Enter the index you want to customize:  4
Generating custom json and exiting ...
Process of generating custom config file for AutoML has been
completed successfully.
'custom_housing.json' file is generated successfully under the current
working directory.
```
### get_persisted_tables
Use the get_persisted_tables function to get the list of the tables that are persisted in the database.
Note:
You are responsible for keeping track of the persistent tables and persistent table cleanup.
get_persisted_tables returns a dictionary containing the list of table names that mapped to the stage at
which it was generated.
#### Parameters
There are no parameters for this function.
#### Example
Create an instance of the AutoML called "obj" by referring one of the following methods:
* AutoML()
* AutoRegressor()
* AutoClassifier()
The 'persist' argument must be set to True in the AutoML object.
```python
>>> obj = AutoML(verbose=2, max_models=10, persist=True)
```
Load and fit the data.
```python
>>> load_example_data("teradataml", "titanic")
titanic_data = DataFrame("titanic")
>>> obj.fit(data = titanic_data, target_column = titanic.survived)
```
Get the list of tables that are persisted in the database.
```python
>>> obj.get_persisted_tables()
```
### deploy
Use the deploy() function to save models to the specified table.
Note:
If 'ranks' is provided, specified models in 'ranks' will be saved and ranks will be reassigned to specified
models based on the order of the leaderboard, non-specified models will be ignored.
Raises TeradataMlException.
Required argument:
* table_name specifies the table name to which the models information is to be saved.
  Types: int
Optional arguments:
* top_n specifies the top n models to be saved.
  Note:
    If ranks is not provided, the function saves the top 'top_n' models.
  Default value: 3
  Types: int
* ranks specifies the ranks for the models to be saved.
  Note:
    If ranks is provided, then top_n is ignored.
  Types: int or list of int or range object.
#### Example setup: Create an instance of the AutoML called "obj" by referring
#### "AutoML() or AutoRegressor() or AutoClassifier()" method
```python
>>> obj = AutoML(task_type="Classification")
>>> obj.fit(data = data, target_column = target_column)
```
#### Example 1: Save top 3 models to the specified table
```python
>>> obj.deploy("model_table")
```
#### Example 2: Save top n models to the specified table
```python
>>> obj.deploy("model_table", top_n=5)
```
#### Example 3: Save models based on specified ranks to the specified table
```python
>>> obj.deploy("model_table", ranks=[1, 3, 5])
```
#### Example 4: Save models based on specified rank range to the specified table
```python
>>> obj.deploy("model_table", ranks=range(2,6))
```
### load
Use the load() function to load models information from the specified table. Returns Pandas DataFrame
with loaded models information.
Raises TeradataMlException.
Required argument:
* table_name specifies the table name from which models to be loaded.
  Types: str
#### Example 1: Create an instance of the AutoML called "obj" by referring
#### "AutoML() or AutoRegressor() or AutoClassifier()" method
```python
>>> obj = AutoML()
```
#### Example 2: Load models from the specified table
```python
>>> tab = obj.load("model_table")
```
### remove_saved_models
Use the remove_saved_models() function to remove the specified table containing saved models.
Note:
If any data table result table is not present inside the database, then it will be skipped.
Raises TeradataMlException.
Required argument:
* table_name specifies the table name containing saved models.
  Types: str
#### Example 1: Create an instance of the AutoML called "obj" by referring
#### "AutoML() or AutoRegressor() or AutoClassifier()" method
```python
>>> obj = AutoML()
```
#### Example 2: Remove saved models from the specified table
Note:
remove_saved_models() removes all information related to the saved models. This can include
necessary information for running other deployed models if the "persist" parameter is set to True
during AutoML fitting.
```python
>>> obj.remove_saved_models("model_table")
```
### visualize
Use the visualize function to visualize the data using various plots such as heatmap, pair plot, histogram,
univariate plot, count plot, box plot, and target distribution.
#### Required Parameters
data
    Specifies the input teradataml DataFrame for plotting
target_column
    Specifies the name of the target column in "data".
    Note:
      "target_column" must be of numeric type.
#### Optional Parameters
plot_type
    Specifies the type of plot to be displayed.
    Permitted values:
    * "heatmap": Displays a heatmap of feature correlations.
    * "pair": Displays a pair plot of features.
    * "density": Displays a density plot of features.
    * "count": Displays a count plot of categorical features.
    * "box": Displays a box plot of numerical features.
* "target": Displays the distribution of the target variable.
    * "all": Displays all the plots.
    Default value: "target"
length
    Specifies the length of the plot.
    Default value: 10
breadth
    Specifies the breadth of the plot.
    Default value: 8
columns
    Specifies the column names to be used for plotting.
max_features
    Specifies the maximum number of features to be used for plotting.
    Default value: 10
    Note:
      It applies separately to categorical and numerical features.
problem_type
    Specifies the type of problem.
    Permitted values:
    * 'regression'
    * 'classification'
#### Example setup
The following examples can be run with either AutoML, AutoClassifier, AutoRegressor, or Autodataprep.
Import a preferred module to run the example.
The following examples use AutoML module.
```python
>>> from teradataml import AutoML
>>> from teradataml import DataFrame
```