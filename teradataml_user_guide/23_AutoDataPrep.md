# AutoDataPrep

```python
SeqNum
0               0  CLASS_1       78       21   0.787879  0.715596  0.750000
109
1               1  CLASS_2       31       48   0.607595  0.695652  0.648649
69
ROC-AUC :
AUC GINI
0.6067012365376944 0.21340247307538873
threshold_value tpr fpr
0.04081632653061224 0.6956521739130435 0.28440366972477066
0.08163265306122448 0.6956521739130435 0.28440366972477066
0.1020408163265306 0.6956521739130435 0.28440366972477066
0.12244897959183673 0.6956521739130435 0.28440366972477066
0.16326530612244897 0.6956521739130435 0.28440366972477066
0.18367346938775508 0.6956521739130435 0.28440366972477066
0.14285714285714285 0.6956521739130435 0.28440366972477066
0.061224489795918366 0.6956521739130435 0.28440366972477066
0.02040816326530612 0.6956521739130435 0.28440366972477066
0.0 1.0 1.0
Confusion Matrix :
array([[78, 31],
[21, 48]], dtype=int64)
>>> prediction.head()
id  prediction      prob  survived
101        0.0  0.842330         0
40         0.0  0.613704         0
120        0.0  0.883461         0
122        0.0  0.865047         0
61         1.0  0.797549         1
141        0.0  0.876889         0
162        0.0  0.865844         0
78         1.0  0.655147         0
99         1.0  0.950835         1
95         0.0  0.582591         1
```
## AutoDataPrep
AutoDataPrep is a core component of the AutoML framework that automates data preparation tasks like
cleaning, transforming, and optimizing datasets. It simplifies complex, time-consuming data science steps,
allowing users to focus on model building and analysis.
AutoDataPrep manages missing data, feature scaling, encoding, and other preprocessing, transforming
raw data into machine learning-ready formats, enhancing efficiency and speeding up insights in
model development.
* Key Features of AutoDataPrep
* Methods of AutoDataPrep
* AutoDataPrep Examples
### Key Features of AutoDataPrep
Key features of AutoDataPrep:
* Automated data cleaning: Automatically detects and handles missing values, outliers, and duplicates.
* Transformation: Provides efficient feature scaling, encoding categorical data, and
  normalizing datasets.
* Optimization: Applies best practices for data preparation to enhance model performance
  during training.
* Problem-specific preparation: Tailors data preparation techniques based on the specific data problem,
  whether it involves regression or classification tasks.
Use this tool to streamline your machine learning pipeline without delving into the intricate details of data
preparation. At the end of the AutoDataPrep process, a fully prepared and optimized dataset is generated,
ready for model training.
### Methods of AutoDataPrep
To facilitate the key features mentioned in the previous section, teradataml AutoDataPrep provides the
following methods:
* AutoDataPrep.__init__: Create instance for AutoDataPrep.
* fit: Fit over given dataset.
* get_data: Retrieve the set of data after Auto Data preparation.
* load: Load the saved datasets from the database.
* deploy: Persist the datasets generated by AutoDataPrep in the database.
* delete_data: Delete the deployed dataset from the database.
* visualize: Generate visualizations to analyze and understand the underlying patterns in the data.
#### AutoDataPrep.__init__
AutoDataPrep simplifies the data preparation process by automating the different aspects of
data cleaning and transformation, enabling seamless exploration, transformation, and optimization
of datasets.
The function returns an instance of AutoDataPrep.
#### Optional Arguments
task_type
    Specifies the task type for AutoDataPrep, whether to apply regression OR classification on
    the provided dataset. If you want AutoDataPrep() to decide the task type automatically, set
    task_type to "Default".
    Permitted values: "Regression", "Classification", "Default"
    Default value: "Default"
verbose
    Specifies the detailed execution steps based on verbose level.
    Permitted values:
    Default value: 0
volatile
    Specifies whether to put the interim results of the functions in a volatile table or not. When
    set to True, results are stored in a volatile table, otherwise not.
    Default value: False
persist
    Specifies whether to persist the interim results of the functions in a table or not. When set
    to True, results are persisted in a table; otherwise, results are garbage collected at the end
    of the session.
    Default value: False
#### fit
Use the fit() function to fit the data for auto data preparation.
#### Required Parameters
data
    Specifies the input data to be used for auto data preparation.
target_column
    Specifies the target column to be used for auto data preparation.
#### Example setup
Note:
* Get the connection to the database to execute the function.
* You must import the required functions mentioned in the example from teradataml
* The function returns an error if not supported on the database you are connected to
Load the example data.
```python
>>> load_example_data("teradataml", "titanic")
```
Create teradataml DataFrames.
```python
>>> titanic = DataFrame.from_table("titanic")
```
#### Example 1: Run AutoDataPrep for classification problem
Titanic dataset is used to predict the survival of passengers.
Create an instance of AutoDataPrep.
```python
>>> aprep_obj = AutoDataPrep(task_type="Classification", verbose=2)
```
Fit the data.
```python
>>> aprep_obj.fit(titanic, titanic.survived)
```
#### get_data
Use the get_data() function to retrieve the datas after auto data preparation. This function returns a
dictionary of DataFrames containing the data after auto data preparation.
This function uses no parameters.
#### Example setup
Note:
* Get the connection to the database to execute the function.
* You must import the required functions mentioned in the example from teradataml
* The function returns an error if not supported on the database you are connected to.
Load the example data.
```python
>>> load_example_data("teradataml", "titanic")
```
Create teradataml DataFrames.
```python
>>> titanic = DataFrame.from_table("titanic")
```
#### Example 1: Run AutoDataPrep for classification problem
Titanic dataset is used to predict the survival of passengers.
Create an instance of AutoDataPrep.
```python
>>> aprep_obj = AutoDataPrep(task_type="Classification", verbose=2)
```
Fit the data.
```python
>>> aprep_obj.fit(titanic, titanic.survived)
```
Retrieve the data after auto data preparation.
```python
>>> datas = aprep_obj.get_data()
```
#### load
Use the load() function to load the AutoDataPrep generated data from the database in the session to
use it for model training or scoring. This function returns a dictionary of DataFrames containing the datas
generated from AutoDataPrep.
#### Required Parameter
table_name
    Specifies the name of the table containing the information of deployed datasets in
    the database.
#### Example: Load data
Create an instance of AutoDataPrep.
```python
>>> aprep_obj = AutoDataPrep()
```
Load the data from the table.
```python
>>> data = aprep_obj.load("table_name")
```
Retrieve the data.
```python
>>> print(data)
```
#### deploy
Use the deploy() function to deploy the AutoDataPrep-generated data to the database, i.e., save the data
in the database.
#### Required Parameter
table_name
    Specifies the name of the table to store the information of deployed datasets in
    the database.
#### Example setup
* Create an instance of the AutoDataPrep.
* Perform fit() operation on the AutoDataPrep object.
* Deploy the data to the table.
* From teradataml, import AutoDataPrep.
* Load the example data.
```python
>>> load_example_data("teradataml", "titanic")
>>> titanic = DataFrame.from_table("titanic")
```
#### Example 1: Deploy data
Create an instance of AutoDataPrep.
```python
>>> aprep_obj = AutoDataPrep(task_type="Classification", verbose=2)
```
Fit the data.
```python
>>> aprep_obj.fit(titanic, titanic.survived)
```
Deploy the data to the table.
```python
>>> aprep_obj.deploy("table_name")
```
#### delete_data
Use the delete_data() function to delete the deployed datasets from the database.
#### Required Parameter
table_name
    Specifies the name of the table containing the deployed datasets.
#### Optional Parameter
fs_method
    Specifies the name of the feature selection method to delete from the deployed datasets.
    Permitted values: "lasso", "rfe", "pca".
    Default value: None
    Note:
      If "fs_method" is None, then the function deletes all the deployed datasets.
#### Example setup
Create an instance of the AutoDataPrep.
Fit the data.
Deploy the data to the table.
Remove the deployed data from the table.
#### Example 1: Remove the deployed data from the table within the
#### AutoDataPrep object
```python
from teradataml import AutoDataPrep
```
Load the example data.
```python
>>> load_example_data("teradataml", "titanic")
>>> titanic = DataFrame.from_table("titanic")
```
Create an instance of AutoDataPrep.
```python
>>> aprep_obj = AutoDataPrep(task_type="Classification", verbose=2)
```
Fit the data.
```python
>>> aprep_obj.fit(titanic, titanic.survived)
```
Deploy the data to the database.
```python
>>> aprep_obj.deploy("table_name")
```
Remove lasso deployed data from the table.
```python
>>> aprep_obj.delete_data("table_name", fs_method="lasso")
```
#### Example 2: Remove the deployed data from the table using different instance
#### of AutoDataPrep object
Create an instance of AutoDataPrep.
```python
>>> aprep_obj2 = AutoDataPrep()
```
Remove lasso and pca deployed data from the table.
```python
>>> aprep_obj2.delete_data("table_name", fs_method=["lasso", "pca"])
```
#### visualize
Use the visualize() function to visualize the data using various plots such as heatmap, pair plot, histogram,
univariate plot, count plot, box plot, and target distribution.
#### Required Parameters
data
    Specifies the input teradataml DataFrame for plotting.
target_column
    Specifies the name of the target column in "data".
    Note:
      "target_column" must be of numeric type.
#### Optional Parameters
plot_type
    Specifies the type of plot to be displayed.
    Permitted values:
    * "heatmap": Displays a heatmap of feature correlations.
    * "pair": Displays a pair plot of features.
    * "density": Displays a density plot of features.
    * "count": Displays a count plot of categorical features.
    * "box": Displays a box plot of numerical features.
    * "target": Displays the distribution of the target variable.
    * "all": Displays all the plots.
    Default value: "target"
length
    Specifies the length of the plot.
    Default value: 10
breadth
    Specifies the breadth of the plot.
    Default value: 8
columns
    Specifies the column names to be used for plotting.
max_features
    Specifies the maximum number of features to be used for plotting.
    Default value: 10
    Note:
      It applies separately to categorical and numerical features.
problem_type
    Specifies the type of problem.
    Permitted values:
    * 'regression'
    * 'classification'
#### Example setup
Import either of AutoML or AutoClassifier or AutoRegressor or AutoDataPrep from teradataml.
```python
>>> from teradataml import AutoML
>>> from teradataml import DataFrame
>>> load_example_data("teradataml", "titanic")
>>> titanic_data = DataFrame("titanic")
```
#### Example 1: Visualize the data using AutoML class
```python
>>> AutoML.visualize(data = titanic_data,
...                  target_column = 'survived',
...                  plot_type = ['heatmap', 'pair', 'histogram', 'target'],
...                  length = 10,
...                  breadth = 8,
...                  max_features = 10,
...                  problem_type = 'classification')
```
#### Example 2: Visualize the data using AutoDataPrep class
```python
>>> from teradataml import AutoDataPrep
>>> obj = AutoDataPrep(task_type="classification")
>>> obj.fit(data = titanic_data, target_column = 'survived')
```
Retrieve the data from AutoDataPrep object
```python
>>> datas = obj.get_data()
>>> AutoDataPrep.visualize(data = datas['lasso_train'],
...                        target_column = 'survived',
...                        plot_type = 'all'
...                        length = 20,
...                        breadth = 15)
```
### AutoDataPrep Examples
* Example 1: AutoDataPrep for Regression problem
* Example 2: AutoDataPrep for Classification Problem
#### Example 1: AutoDataPrep for Regression problem
This example prepares insurance data for regression analysis by cleaning, transforming, and optimizing
demographic and health-related features.
Run AutoDataprep to get the optimized data with the following specifications:
* Set task_type to Regression.
* Set the verbose level to 2 to obtain detailed information about intermediate steps.
1. Load the insurance dataset.
```python
>>> load_example_data("teradataml", "insurance")
```
2. Create a DataFrame.
```python
>>> insurance = DataFrame.from_table("insurance")
```
3. Create an instance of AutoDataPrep.
```python
>>> adp = AutoDataPrep(task_type='Regression', verbose=2)
```
4. Fit the data.
```python
>>> adp.fit(insurance, insurance.charges)
1. Feature Exploration ->2. Feature Engineering ->3. Data Preparation
Feature Exploration started ...
Data Overview:
Total Rows in the data: 1338
Total Columns in the data: 7
Column Summary:
ColumnName Datatype NonNullCount NullCount BlankCount
ZeroCount PositiveCount NegativeCount NullPercentage
NonNullPercentage
children INTEGER 1338 0 None 574 764 0 0.0
100.0
smoker VARCHAR(20) CHARACTER SET LATIN 1338 0 0 None None
None 0.0 100.0
age INTEGER 1338 0 None 0 1338 0 0.0
100.0
charges FLOAT 1338 0 None 0 1338 0 0.0
100.0
region VARCHAR(20) CHARACTER SET LATIN 1338 0 0 None None
None 0.0 100.0
bmi FLOAT 1338 0 None 0 1338 0 0.0
100.0
sex VARCHAR(20) CHARACTER SET LATIN 1338 0 0 None None
None 0.0 100.0
Statistics of Data:
func age bmi children charges
min 18 15.96 0 1121.874
std 14.05 6.098 1.205 12110.011
25% 27 26.296 0 4740.287
50% 39 30.4 1 9382.033
75% 51 34.694 2 16639.913
max 64 53.13 5 63770.428
mean 39.207 30.663 1.095 13270.422
count 1338 1338 1338 1338
Categorical Columns with their Distinct values:
ColumnName                DistinctValueCount
sex                       2
smoker                    2
region                    4
No Futile columns found.
Install seaborn and matplotlib libraries to visualize the data.
Columns with outlier percentage :-
ColumnName  OutlierPercentage
0    charges          10.388640
1        bmi           0.672646
1. Feature Exploration ->2. Feature Engineering ->3. Data Preparation
Feature Engineering started ...
Handling duplicate records present in dataset ...
Updated dataset sample after removing 1 duplicate records:
age sex bmi children smoker region charges
40 female 36.19 0 no southeast 5920.1041
34 female 37.335 2 no northwest 5989.52365
34 female 27.5 1 no southwest 5003.853
19 female 27.9 0 yes southwest 16884.924
19 female 28.6 5 no southwest 4687.797
61 female 39.1 2 no southwest 14235.072
61 female 29.92 3 yes southeast 30942.1918
61 female 22.04 0 no northeast 13616.3586
19 male 24.6 1 no southwest 1837.237
34 female 31.92 1 yes northeast 37701.8768
1337 rows X 7 columns
Remaining Rows in the data: 1337
Remaining Columns in the data: 7
Total time to handle duplicate records: 6.30 sec
Handling less significant features from data ...
Analysis indicates all categorical columns are significant. No action
Needed.
Total time to handle less significant features: 18.70 sec
Handling Date Features ...
Analysis Completed. Dataset does not contain any feature related to dates. No
action needed.
Total time to handle date features: 0.00 sec
Checking Missing values in dataset ...
Analysis Completed. No Missing Values
Detected.
Total time to find missing values in data: 9.00 sec
Imputing Missing Values ...
Analysis completed. No imputation
required.
Time taken to perform imputation: 0.00 sec
Performing encoding for categorical columns ...
ONE HOT Encoding these Columns:
['sex', 'smoker', 'region']
Sample of dataset after performing one hot encoding:
age sex_0 sex_1 bmi children smoker_0 smoker_1
region_0 region_1 region_2 region_3 charges id
19 1 0 24.51 1 1 0 0 1 0
0 2709.1119 171
19 0 1 28.4 1 1 0 0 0 0
1 1842.519 43
19 1 0 30.495 0 1 0 0 1 0
0 2128.43105 155
19 0 1 27.835 0 1 0 0 1 0
0 1635.73365 95
19 1 0 37.43 0 1 0 0 1 0
0 2138.0707 107
19 1 0 24.7 0 1 0 0 0 0
1 1737.376 91
19 1 0 39.615 1 1 0 0 1 0
0 2730.10785 215
19 1 0 24.605 1 1 0 0 1 0
0 2709.24395 223
19 0 1 36.955 0 0 1 0 1 0
0 36219.40545 79
19 1 0 21.7 0 0 1 0 0 0
1 13844.506 99
1337 rows X 13 columns
Time taken to encode the columns: 27.40 sec
1. Feature Exploration ->2. Feature Engineering ->3. Data Preparation
Data preparation started ...
Outlier preprocessing ...
Columns with outlier percentage :-
ColumnName  OutlierPercentage
0    charges          10.396410
1        bmi           0.673149
Deleting rows of these columns:
['bmi']
Sample of dataset after removing outlier rows:
age sex_0 sex_1 bmi children smoker_0 smoker_1
region_0 region_1 region_2 region_3 charges id
40 0 1 29.355 1 1 0 0 1 0
0 6393.60345 98
40 0 1 32.3 2 1 0 0 1 0
0 6986.697 82
40 0 1 41.69 0 1 0 0 0 1
0 5438.7491 78
40 0 1 30.875 4 1 0 0 1 0
0 8162.71625 26
40 1 0 25.46 1 1 0 1 0 0
0 7077.1894 18
40 1 0 28.12 1 0 1 1 0 0
0 22331.5668 42
40 1 0 32.775 2 0 1 0 1 0
0 40003.33225 70
40 1 0 29.81 1 1 0 0 0 1
0 6500.2359 74
40 0 1 22.705 2 1 0 1 0 0
0 7173.35995 62
40 0 1 26.315 1 1 0 0 1 0
0 6389.37785 10
1328 rows X 13 columns
Time Taken by Outlier processing: 43.44 sec
Feature selection using lasso ...
feature selected by lasso:
['children', 'smoker_0', 'region_3', 'region_2', 'smoker_1', 'age',
'region_0', 'region_1', 'bmi']
Total time taken by feature selection: 0.64 sec
scaling Features of lasso data ...
columns that will be scaled:
['children', 'age', 'bmi']
Dataset sample after scaling:
id smoker_0 region_3 region_2 smoker_1
charges region_0 region_1 children age bmi
6 1 0 0 0 8059.6791 0 1
1.5757993454038124 0.05563012376023704 -0.3120480999672465
8 0 0 1 1 30942.1918 0 0
1.5757993454038124 1.5516888425890614 -0.1042759435566039
9 1 0 0 0 5989.5237 0 1
0.7476784389153823 -0.3718152244765699 1.148269210740074
10 1 0 0 0 6389.3778 0
1 -0.0804424675730478 0.05563012376023704 -0.7132341743373894
12 1 0 0 0 13616.3586 1
0 -0.9085633740614779 1.5516888425890614 -1.4353691082036473
13 1 1 0 0 5003.853 0
0 -0.0804424675730478 -0.3718152244765699 -0.5130634382832341
11 1 1 0 0 1837.237 0
0 -0.0804424675730478 -1.4404285950685871 -1.0029327501457244
7 0 1 0 1 16884.924 0
0 -0.9085633740614779 -1.4404285950685871 -0.445495257336684
5 0 0 0 1 37701.8768 1
0 -0.0804424675730478 -0.3718152244765699 0.2335649611761481
4 1 1 0 0 14235.072 0 0
0.7476784389153823 1.5516888425890614 1.4464138091667278
1328 rows X 11 columns
Total time taken by feature scaling: 67.31 sec
Feature selection using rfe ...
feature selected by RFE:
['children', 'sex_1', 'smoker_0', 'region_3', 'region_2', 'smoker_1',
'sex_0', 'age', 'region_0', 'region_1', 'bmi']
Total time taken by feature selection: 20.10 sec
scaling Features of rfe data ...
columns that will be scaled:
['r_children', 'r_age', 'r_bmi']
Dataset sample after scaling:
id r_sex_1 r_region_0 r_smoker_0 r_region_2 r_region_1
charges r_sex_0 r_smoker_1 r_region_3 r_children r_age
r_bmi
6 0 0 1 0 1 8059.6791 1 0
0 1.5757993454038124 0.05563012376023704 -0.3120480999672465
8 0 0 0 1 0 30942.1918 1 1
0 1.5757993454038124 1.5516888425890614 -0.1042759435566039
9 0 0 1 0 1 5989.5237 1 0
0 0.7476784389153823 -0.3718152244765699 1.148269210740074
10 1 0 1 0 1 6389.3778 0 0
0 -0.0804424675730478 0.05563012376023704 -0.7132341743373894
12 0 1 1 0 0 13616.3586 1 0
0 -0.9085633740614779 1.5516888425890614 -1.4353691082036473
13 0 0 1 0 0 5003.853 1 0
1 -0.0804424675730478 -0.3718152244765699 -0.5130634382832341
11 1 0 1 0 0 1837.237 0 0
1 -0.0804424675730478 -1.4404285950685871 -1.0029327501457244
7 0 0 0 0 0 16884.924 1 1
1 -0.9085633740614779 -1.4404285950685871 -0.445495257336684
5 0 1 0 0 0 37701.8768 1 1
0 -0.0804424675730478 -0.3718152244765699 0.2335649611761481
4 0 0 1 0 0 14235.072 1 0
1 0.7476784389153823 1.5516888425890614 1.4464138091667278
1328 rows X 13 columns
Total time taken by feature scaling: 74.77 sec
scaling Features of pca data ...
columns that will be scaled:
['age', 'bmi', 'children']
Dataset sample after scaling:
id sex_1 smoker_0 region_3 region_2 smoker_1
charges sex_0 region_0 region_1 age bmi children
33 1 1 0 0 0 4894.7533 0 0
1 -0.37181522447657034 -0.889756047060253 -0.08044246757304761
80 1 1 0 0 0 12950.0712 0 0
1 1.5516888425890631 1.3247910834629393 -0.9085633740614759
88 1 1 0 0 0 13143.33665 0 1
0 1.5516888425890631 0.5063714917478457 -0.9085633740614759
183 1 1 0 0 0 1627.28245 0 0
1 -1.4404285950685891 -1.4835114371280653 -0.9085633740614759
43 1 1 1 0 0 1842.519 0 0
0 -1.4404285950685891 -0.3610350311534957 -0.08044246757304761
10 1 1 0 0 0 6389.37785 0 0
1 0.055630123760237106 -0.7132341743373897 -0.08044246757304761
62 1 1 0 0 0 7173.35995 0 1
0 0.055630123760237106 -1.3230370073800082 0.7476784389153807
98 1 1 0 0 0 6393.60345 0 0
1 0.055630123760237106 -0.19971599914360616 -0.08044246757304761
127 0 1 1 0 0 1744.465 1 0
0 -1.4404285950685891 -0.12454639784056873 -0.9085633740614759
16 1 1 0 1 0 12557.6053 0 0
0 1.5516888425890631 0.17444280284791705 -0.9085633740614759
1328 rows X 13 columns
Total time taken by feature scaling: 70.63 sec
Dimension Reduction using pca ...
PCA columns:
['col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7']
Total time taken by PCA: 5.23 sec
Completed: ｜⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾｜
100% - 12/12
```
5. Retrieve the data.
```python
>>> datas = adp.get_data()
>>> print(datas)
{'lasso_train':    id  smoker_0  region_3  region_2  smoker_1     charges
region_0  region_1  children       age       bmi
0   6         1         0         0         0   8059.6791
0         1  1.575799  0.055630 -0.312048
1   8         0         0         1         1  30942.1918
0         0  1.575799  1.551689 -0.104276
2   9         1         0         0         0   5989.5237
0         1  0.747678 -0.371815  1.148269
3  10         1         0         0         0   6389.3778
0         1 -0.080442  0.055630 -0.713234
4  12         1         0         0         0  13616.3586
1         0 -0.908563  1.551689 -1.435369
5  13         1         1         0         0   5003.8530
0         0 -0.080442 -0.371815 -0.513063
6  11         1         1         0         0   1837.2370
0         0 -0.080442 -1.440429 -1.002933
7   7         0         1         0         1  16884.9240
0         0 -0.908563 -1.440429 -0.445495
8   5         0         0         0         1  37701.8768
1         0 -0.080442 -0.371815  0.233565
9   4         1         1         0         0  14235.0720
0         0  0.747678  1.551689  1.446414,
'rfe_train':    id  r_sex_1  r_region_0  r_smoker_0  r_region_2
r_region_1     charges  r_sex_0  r_smoker_1  r_region_3  r_children
r_age     r_bmi
0   6        0           0           1           0           1
8059.6791        1           0           0    1.575799  0.055630 -0.312048
1   8        0           0           0           1           0
30942.1918        1           1           0    1.575799  1.551689 -0.104276
2   9        0           0           1           0           1
5989.5237        1           0           0    0.747678 -0.371815  1.148269
3  10        1           0           1           0           1
6389.3778        0           0           0   -0.080442  0.055630 -0.713234
4  12        0           1           1           0           0
13616.3586        1           0           0   -0.908563  1.551689 -1.435369
5  13        0           0           1           0           0
5003.8530        1           0           1   -0.080442 -0.371815 -0.513063
6  11        1           0           1           0           0
1837.2370        0           0           1   -0.080442 -1.440429 -1.002933
7   7        0           0           0           0           0
16884.9240        1           1           1   -0.908563 -1.440429 -0.445495
8   5        0           1           0           0           0
37701.8768        1           1           0   -0.080442 -0.371815  0.233565
9   4        0           0           1           0           0
14235.0720        1           0           1    0.747678  1.551689  1.446414,
'pca_train':     id     col_0     col_1     col_2     col_3     col_4
col_5     col_6     col_7      charges
0   10 -0.501049  0.212461  0.497235  0.681457 -0.464433 -0.567898
-0.465134 -0.306924   6389.37785
1   80  1.651779 -1.312731  0.555223  0.649412 -0.495789 -0.500910
-0.498871 -0.631955  12950.07120
2   21 -0.554054  0.965049 -0.091233  0.896880  1.159215 -0.295192
0.025567  0.685346  18972.49500
3   62 -0.695502  1.170791  0.705762  0.718531 -0.333932  0.062303
0.805416 -0.139308   7173.35995
4   88  1.077202 -1.057424  1.060134  0.724899 -0.360972  0.124439
0.752513 -0.435334  13143.33665
5   33 -0.903409  0.287616  0.283118  0.672305 -0.469241 -0.570349
-0.464089 -0.287757   4894.75330
6  127 -1.301304 -0.752830 -0.750830 -0.789391 -0.317223  0.741478
-0.375274  0.175844   1744.46500
7  183 -2.250650 -0.246800  0.010147  0.684306 -0.478755 -0.579147
-0.481020 -0.220729   1627.28245
8   81 -1.382234 -0.424317  0.746897 -0.647251 -0.107673  0.109855
0.752249 -0.225352   4992.37640
9   16  0.979263 -1.020987  1.089544  0.724797 -0.178979 -0.450116
0.186819  0.754266  12557.60530}
```
6. Deploy the generated data to the database.
Note:
  Deployed data can be used across different session using load() api.
```python
>>> adp.deploy(table_name='ins_deploy')
Data deployed successfully to the table:  ins_deploy
```
7. Load the deployed data from the database.
a. Create an instance of autodataprep.
```python
>>> ap = AutoDataPrep()
```
b. Load the data from database.
```python
>>> data = ap.load(table_name='ins_deploy')
>>> data
{'lasso_train':    id  smoker_0  region_3  region_2  smoker_1
charges  region_0  region_1  children       age       bmi
0   6         1         0         0         0   8059.6791
0         1  1.575799  0.055630 -0.312048
1   8         0         0         1         1  30942.1918
0         0  1.575799  1.551689 -0.104276
2   9         1         0         0         0   5989.5237
0         1  0.747678 -0.371815  1.148269
3  10         1         0         0         0   6389.3778
0         1 -0.080442  0.055630 -0.713234
4  12         1         0         0         0  13616.3586
1         0 -0.908563  1.551689 -1.435369
5  13         1         1         0         0   5003.8530
0         0 -0.080442 -0.371815 -0.513063
6  11         1         1         0         0   1837.2370
0         0 -0.080442 -1.440429 -1.002933
7   7         0         1         0         1  16884.9240
0         0 -0.908563 -1.440429 -0.445495
8   5         0         0         0         1  37701.8768
1         0 -0.080442 -0.371815  0.233565
9   4         1         1         0         0  14235.0720
0         0  0.747678  1.551689  1.446414,
'rfe_train':    id  r_sex_1  r_region_0  r_smoker_0  r_region_2
r_region_1     charges  r_sex_0  r_smoker_1  r_region_3  r_children
r_age     r_bmi
0   6        0           0           1           0
1   8059.6791        1           0           0    1.575799
0.055630 -0.312048
1   8        0           0           0           1
0  30942.1918        1           1           0    1.575799
1.551689 -0.104276
2   9        0           0           1           0
1   5989.5237        1           0           0    0.747678
-0.371815  1.148269
3  10        1           0           1           0
1   6389.3778        0           0           0   -0.080442
0.055630 -0.713234
4  12        0           1           1           0
0  13616.3586        1           0           0   -0.908563
1.551689 -1.435369
5  13        0           0           1           0
0   5003.8530        1           0           1   -0.080442
-0.371815 -0.513063
6  11        1           0           1           0
0   1837.2370        0           0           1   -0.080442
-1.440429 -1.002933
7   7        0           0           0           0
0  16884.9240        1           1           1   -0.908563
-1.440429 -0.445495
8   5        0           1           0           0
0  37701.8768        1           1           0   -0.080442
-0.371815  0.233565
9   4        0           0           1           0
0  14235.0720        1           0           1    0.747678
1.551689  1.446414,
'pca_train':     id     col_0     col_1     col_2     col_3
col_4     col_5     col_6     col_7      charges
0   10 -0.501049  0.212461  0.497235  0.681457 -0.464433 -0.567898
-0.465134 -0.306924   6389.37785
1   80  1.651779 -1.312731  0.555223  0.649412 -0.495789 -0.500910
-0.498871 -0.631955  12950.07120
2   21 -0.554054  0.965049 -0.091233  0.896880  1.159215 -0.295192
0.025567  0.685346  18972.49500
3   62 -0.695502  1.170791  0.705762  0.718531 -0.333932  0.062303
0.805416 -0.139308   7173.35995
4   88  1.077202 -1.057424  1.060134  0.724899 -0.360972  0.124439
0.752513 -0.435334  13143.33665
5   33 -0.903409  0.287616  0.283118  0.672305 -0.469241 -0.570349
-0.464089 -0.287757   4894.75330
6  127 -1.301304 -0.752830 -0.750830 -0.789391 -0.317223  0.741478
-0.375274  0.175844   1744.46500
7  183 -2.250650 -0.246800  0.010147  0.684306 -0.478755 -0.579147
-0.481020 -0.220729   1627.28245
8   81 -1.382234 -0.424317  0.746897 -0.647251 -0.107673  0.109855
0.752249 -0.225352   4992.37640
9   16  0.979263 -1.020987  1.089544  0.724797 -0.178979 -0.450116
0.186819  0.754266  12557.60530}
```
8. Delete the deployed data.
Deletion of data can be partial or complete.
  * Partial delete using fs_method:
```python
>>> ap.delete_data(table_name='titanic_deploy', fs_method='pca')
Removed pca_train table successfully.
```
  * Remove all data (complete):
```python
>>> ap.delete_data(table_name='titanic_deploy')
Removed lasso_train table successfully.
Removed rfe_train table successfully.
Deployed data removed successfully.
```
#### Example 2: AutoDataPrep for Classification Problem
This example prepares Titanic passenger data for classification by cleaning, transforming, and optimizing
features for further analysis.
Run AutoDataprep to get the optimized data with the following specifications::
* Set task_type to Classification.
* Set the verbose level to 2 to obtain detailed information about intermediate steps.
1. Load the titanic dataset.
```python
>>> load_example_data("teradataml", "titanic")
```
2. Create the DataFrame.
```python
>>> titanic = DataFrame.from_table("titanic")
```
3. Create an instance of AutoDataPrep.
```python
>>> acls = AutoDataPrep(task_type='classification', verbose=2)
```
4. Fit the data.
```python
>>> acls.fit(titanic, titanic.survived)
1. Feature Exploration ->2. Feature Engineering ->3. Data Preparation
Feature Exploration started ...
Data Overview:
Total Rows in the data: 891
Total Columns in the data: 12
Column Summary:
ColumnName Datatype NonNullCount NullCount BlankCount
ZeroCount PositiveCount NegativeCount NullPercentage
NonNullPercentage
embarked VARCHAR(20) CHARACTER SET LATIN 889 2 0 None
None None 0.2244668911335578 99.77553310886644
parch INTEGER 891 0 None 678 213 0 0.0
100.0
passenger INTEGER 891 0 None 0 891 0 0.0
100.0
sibsp INTEGER 891 0 None 608 283 0 0.0
100.0
pclass INTEGER 891 0 None 0 891 0 0.0
100.0
name VARCHAR(1000) CHARACTER SET LATIN 891 0 0 None
None None 0.0 100.0
age INTEGER 714 177 None 7 707 0
19.865319865319865 80.13468013468014
ticket VARCHAR(20) CHARACTER SET LATIN 891 0 0 None None
None 0.0 100.0
survived INTEGER 891 0 None 549 342 0 0.0
100.0
sex VARCHAR(20) CHARACTER SET LATIN 891 0 0 None None
None 0.0 100.0
cabin VARCHAR(20) CHARACTER SET LATIN 204 687 0 None None
None 77.10437710437711 22.895622895622896
fare FLOAT 891 0 None 15 876 0 0.0
100.0
Statistics of Data:
func passenger survived pclass age sibsp parch fare
50% 446 0 3 28 0 0 14.454
count 891 891 891 714 891 891 891
mean 446 0.384 2.309 29.679 0.523 0.382 32.204
min 1 0 1 0 0 0 0
max 891 1 3 80 8 6 512.329
75% 668.5 1 3 38 1 0 31
25% 223.5 0 2 20 0 0 7.91
std 257.354 0.487 0.836 14.536 1.103 0.806 49.693
Categorical Columns with their Distinct values:
ColumnName                DistinctValueCount
name                      891
sex                       2
ticket                    681
cabin                     147
embarked                  3
Futile columns in dataset:
ColumnName
name
ticket
Install seaborn and matplotlib libraries to visualize the data.
Columns with outlier percentage :-
ColumnName  OutlierPercentage
0        age          20.763187
1      parch          23.905724
2      sibsp           5.162738
3       fare          13.019080
1. Feature Exploration ->2. Feature Engineering ->3. Data Preparation
Feature Engineering started ...
Handling duplicate records present in dataset ...
Analysis completed. No action
taken.
Total time to handle duplicate records: 3.91 sec
Handling less significant features from data ...
Removing Futile columns:
['ticket', 'name']
Sample of Data after removing Futile columns:
passenger survived pclass sex age sibsp parch fare
cabin embarked id
162 1 2 female 40 0 0 15.75 None S
14
61 0 3 male 22 0 0 7.2292 None C
326 1 1 female 36 0 0 135.6333 C32
C 12
265 0 3 female None 0 0 7.75 None Q
244 0 3 male 22 0 0 7.125 None S
13
122 0 3 male None 0 0 8.05 None S
591 0 3 male 35 0 0 7.125 None S
11
387 0 3 male 1 5 2 46.9 None S
15
530 0 2 male 23 2 1 11.5 None S
469 0 3 male None 0 0 7.725 None Q
891 rows X 11 columns
Total time to handle less significant features: 21.70 sec
Handling Date Features ...
Analysis Completed. Dataset does not contain any feature related to dates. No
action needed.
Total time to handle date features: 0.00 sec
Checking Missing values in dataset ...
Columns with their missing values:
cabin: 687
age: 177
embarked: 2
Deleting rows of these columns for handling missing values:
['embarked']
Sample of dataset after removing 2 rows:
passenger survived pclass sex age sibsp parch fare
cabin embarked id
162 1 2 female 40 0 0 15.75 None S
14
61 0 3 male 22 0 0 7.2292 None C
326 1 1 female 36 0 0 135.6333 C32
C 12
122 0 3 male None 0 0 8.05 None S
387 0 3 male 1 5 2 46.9 None S
15
265 0 3 female None 0 0 7.75 None Q
530 0 2 male 23 2 1 11.5 None S
244 0 3 male 22 0 0 7.125 None S
13
591 0 3 male 35 0 0 7.125 None S
11
469 0 3 male None 0 0 7.725 None Q
889 rows X 11 columns
Dropping these columns for handling missing values:
['cabin']
Sample of dataset after removing 1 columns:
passenger survived pclass sex age sibsp parch fare
embarked id
387 0 3 male 1 5 2 46.9 S 15
40 1 3 female 14 1 0 11.2417 C 10
162 1 2 female 40 0 0 15.75 S 14
265 0 3 female None 0 0 7.75 Q 5
244 0 3 male 22 0 0 7.125 S 13
469 0 3 male None 0 0 7.725 Q 4
61 0 3 male 22 0 0 7.2292 C 8
326 1 1 female 36 0 0 135.6333 C
12
530 0 2 male 23 2 1 11.5 S 9
734 0 2 male 23 0 0 13.0 S 6
889 rows X 10 columns
Total time to find missing values in data: 15.59 sec
Imputing Missing Values ...
Columns with their imputation method:
age: mean
Sample of dataset after Imputation:
passenger survived pclass sex age sibsp parch fare
embarked id
326 1 1 female 36 0 0 135.6333 C
12
591 0 3 male 35 0 0 7.125 S 11
387 0 3 male 1 5 2 46.9 S 15
265 0 3 female 29 0 0 7.75 Q 5
244 0 3 male 22 0 0 7.125 S 13
734 0 2 male 23 0 0 13.0 S 6
40 1 3 female 14 1 0 11.2417 C 10
162 1 2 female 40 0 0 15.75 S 14
530 0 2 male 23 2 1 11.5 S 9
122 0 3 male 29 0 0 8.05 S 7
889 rows X 10 columns
Time taken to perform imputation: 23.12 sec
Performing encoding for categorical columns ...
ONE HOT Encoding these Columns:
['sex', 'embarked']
Sample of dataset after performing one hot encoding:
passenger survived pclass sex_0 sex_1 age sibsp
parch fare embarked_0 embarked_1 embarked_2 id
387 0 3 0 1 1 5 2 46.9 0
0 1 15
448 1 1 0 1 34 0 0 26.55 0
0 1 23
713 1 1 0 1 48 1 0 52.0 0
0 1 27
19 0 3 1 0 31 1 0 18.0 0
0 1 31
263 0 1 0 1 52 1 1 79.65 0
0 1 39
59 1 2 1 0 5 1 2 27.75 0
0 1 43
753 0 3 0 1 33 0 0 9.5 0
0 1 35
856 1 3 1 0 18 0 1 9.35 0
0 1 19
591 0 3 0 1 35 0 0 7.125 0
0 1 11
122 0 3 0 1 29 0 0 8.05 0
0 1 7
889 rows X 13 columns
Time taken to encode the columns: 30.72 sec
1. Feature Exploration ->2. Feature Engineering ->3. Data Preparation
Data preparation started ...
Outlier preprocessing ...
Columns with outlier percentage :-
ColumnName  OutlierPercentage
0        age           7.311586
1      parch          23.959505
2      sibsp           5.174353
3       fare          12.823397
Deleting rows of these columns:
['sibsp', 'age']
Sample of dataset after removing outlier rows:
passenger survived pclass sex_0 sex_1 age sibsp
parch fare embarked_0 embarked_1 embarked_2 id
856 1 3 1 0 18 0 1 9.35 0
0 1 19
713 1 1 0 1 48 1 0 52.0 0
0 1 27
19 0 3 1 0 31 1 0 18.0 0
0 1 31
753 0 3 0 1 33 0 0 9.5 0
0 1 35
59 1 2 1 0 5 1 2 27.75 0
0 1 43
324 1 2 1 0 22 1 1 29.0 0
0 1 47
263 0 1 0 1 52 1 1 79.65 0
0 1 39
448 1 1 0 1 34 0 0 26.55 0
0 1 23
591 0 3 0 1 35 0 0 7.125 0
0 1 11
122 0 3 0 1 29 0 0 8.05 0
0 1 7
785 rows X 13 columns
median inplace of outliers:
['fare', 'parch']
Sample of dataset after performing MEDIAN inplace:
passenger survived pclass sex_0 sex_1 age sibsp
parch fare embarked_0 embarked_1 embarked_2 id
856 1 3 1 0 18 0 0 9.35 0
0 1 19
713 1 1 0 1 48 1 0 52.0 0
0 1 27
19 0 3 1 0 31 1 0 18.0 0
0 1 31
753 0 3 0 1 33 0 0 9.5 0
0 1 35
59 1 2 1 0 5 1 0 27.75 0
0 1 43
324 1 2 1 0 22 1 0 29.0 0
0 1 47
263 0 1 0 1 52 1 0 13.0 0
0 1 39
448 1 1 0 1 34 0 0 26.55 0
0 1 23
591 0 3 0 1 35 0 0 7.125 0
0 1 11
122 0 3 0 1 29 0 0 8.05 0
0 1 7
785 rows X 13 columns
Time Taken by Outlier processing: 61.10 sec
Checking imbalance data ...
Imbalance Not Found.
Feature selection using lasso ...
feature selected by lasso:
['sibsp', 'passenger', 'pclass', 'fare', 'embarked_1', 'sex_1', 'sex_0',
'embarked_0', 'age', 'embarked_2']
Total time taken by feature selection: 5.98 sec
scaling Features of lasso data ...
columns that will be scaled:
['sibsp', 'passenger', 'pclass', 'fare', 'age']
Dataset sample after scaling:
id survived embarked_1 sex_1 sex_0 embarked_0
embarked_2 sibsp passenger pclass fare age
6 0 0 1 0 0 1 0.0
0.8235955056179776 0.5 0.22807017543859648 0.39215686274509803
8 0 0 1 0 1 0 0.0
0.06741573033707865 1.0 0.1268280701754386 0.37254901960784315
9 0 0 1 0 0 1 1.0
0.5943820224719101 0.5 0.20175438596491227 0.39215686274509803
10 1 0 0 1 1 0 0.5
0.043820224719101124 1.0 0.19722280701754386 0.21568627450980393
12 1 0 0 1 1 0 0.0
0.3651685393258427 0.0 0.22807017543859648 0.6470588235294118
13 0 0 1 0 0 1 0.0
0.27303370786516856 1.0 0.125 0.37254901960784315
11 0 0 1 0 0 1 0.0
0.6629213483146067 1.0 0.125 0.6274509803921569
7 0 0 1 0 0 1 0.0
0.13595505617977527 1.0 0.14122807017543862 0.5098039215686274
5 0 1 0 1 0 0 0.0
0.2966292134831461 1.0 0.13596491228070176 0.5098039215686274
4 0 1 1 0 0 0 0.0
0.5258426966292135 1.0 0.1355263157894737 0.5098039215686274
785 rows X 12 columns
Total time taken by feature scaling: 71.44 sec
Feature selection using rfe ...
feature selected by RFE:
['embarked_0', 'sibsp', 'passenger', 'pclass', 'sex_1', 'sex_0', 'age',
'embarked_2', 'fare']
Total time taken by feature selection: 26.95 sec
scaling Features of rfe data ...
columns that will be scaled:
['r_sibsp', 'r_passenger', 'r_pclass', 'r_age', 'r_fare']
Dataset sample after scaling:
id survived r_embarked_0 r_sex_0 r_embarked_2 r_sex_1
r_sibsp r_passenger r_pclass r_age r_fare
6 0 0 0 1 1 0.0 0.8235955056179776
0.5 0.39215686274509803 0.22807017543859648
8 0 1 0 0 1 0.0 0.06741573033707865
1.0 0.37254901960784315 0.1268280701754386
9 0 0 0 1 1 1.0 0.5943820224719101
0.5 0.39215686274509803 0.20175438596491227
10 1 1 1 0 0 0.5 0.043820224719101124
1.0 0.21568627450980393 0.19722280701754386
12 1 1 1 0 0 0.0 0.3651685393258427
0.0 0.6470588235294118 0.22807017543859648
13 0 0 0 1 1 0.0 0.27303370786516856
1.0 0.37254901960784315 0.125
11 0 0 0 1 1 0.0 0.6629213483146067
1.0 0.6274509803921569 0.125
7 0 0 0 1 1 0.0 0.13595505617977527
1.0 0.5098039215686274 0.14122807017543862
5 0 0 1 0 0 0.0 0.2966292134831461
1.0 0.5098039215686274 0.13596491228070176
4 0 0 0 0 1 0.0 0.5258426966292135
1.0 0.5098039215686274 0.1355263157894737
785 rows X 11 columns
Total time taken by feature scaling: 67.15 sec
scaling Features of pca data ...
columns that will be scaled:
['passenger', 'pclass', 'age', 'sibsp', 'fare']
Dataset sample after scaling:
parch id survived embarked_1 sex_1 sex_0 embarked_0
embarked_2 passenger pclass age sibsp fare
0 12 1 0 0 1 1 0
0.3651685393258427 0.0 0.6470588235294118 0.0
0.22807017543859648
0 10 1 0 0 1 1 0
0.043820224719101124 1.0 0.21568627450980393 0.5
0.19722280701754386
0 14 1 0 0 1 0 1
0.18089887640449437 0.5 0.7254901960784313 0.0
0.27631578947368424
0 7 0 0 1 0 0 1
0.13595505617977527 1.0 0.5098039215686274 0.0
0.14122807017543862
0 19 1 0 0 1 0 1
0.9606741573033708 1.0 0.29411764705882354 0.0
0.16403508771929823
0 5 0 1 0 1 0 0
0.2966292134831461 1.0 0.5098039215686274 0.0
0.13596491228070176
0 9 0 0 1 0 0 1
0.5943820224719101 0.5 0.39215686274509803 1.0
0.20175438596491227
0 13 0 0 1 0 0 1
0.27303370786516856 1.0 0.37254901960784315 0.0 0.125
0 11 0 0 1 0 0 1
0.6629213483146067 1.0 0.6274509803921569 0.0 0.125
0 6 0 0 1 0 0 1
0.8235955056179776 0.5 0.39215686274509803 0.0
0.22807017543859648
785 rows X 13 columns
Total time taken by feature scaling: 71.07 sec
Dimension Reduction using pca ...
PCA columns:
['col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5']
Total time taken by PCA: 4.80 sec
Completed: ｜⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾⫾｜
100% - 12/12
```
5. Retrieve the data.
```python
>>> datas = acls.get_data()
>>> print(datas)
{'lasso_train':    id  survived  embarked_1  sex_1  sex_0  embarked_0
embarked_2  sibsp  passenger  pclass      fare       age
0   6         0           0      1      0           0           1    0.0
0.823596     0.5  0.228070  0.392157
1   8         0           0      1      0           1           0    0.0
0.067416     1.0  0.126828  0.372549
2   9         0           0      1      0           0           1    1.0
0.594382     0.5  0.201754  0.392157
3  10         1           0      0      1           1           0    0.5
0.043820     1.0  0.197223  0.215686
4  12         1           0      0      1           1           0    0.0
0.365169     0.0  0.228070  0.647059
5  13         0           0      1      0           0           1    0.0
0.273034     1.0  0.125000  0.372549
6  11         0           0      1      0           0           1    0.0
0.662921     1.0  0.125000  0.627451
7   7         0           0      1      0           0           1    0.0
0.135955     1.0  0.141228  0.509804
8   5         0           1      0      1           0           0    0.0
0.296629     1.0  0.135965  0.509804
9   4         0           1      1      0           0           0    0.0
0.525843     1.0  0.135526  0.509804,
'rfe_train':    id  survived  r_embarked_0  r_sex_0  r_embarked_2
r_sex_1  r_sibsp  r_passenger  r_pclass     r_age    r_fare
0   6         0             0        0             1        1      0.0
0.823596       0.5  0.392157  0.228070
1   8         0             1        0             0        1      0.0
0.067416       1.0  0.372549  0.126828
2   9         0             0        0             1        1      1.0
0.594382       0.5  0.392157  0.201754
3  10         1             1        1             0        0      0.5
0.043820       1.0  0.215686  0.197223
4  12         1             1        1             0        0      0.0
0.365169       0.0  0.647059  0.228070
5  13         0             0        0             1        1      0.0
0.273034       1.0  0.372549  0.125000
6  11         0             0        0             1        1      0.0
0.662921       1.0  0.627451  0.125000
7   7         0             0        0             1        1      0.0
0.135955       1.0  0.509804  0.141228
8   5         0             0        1             0        0      0.0
0.296629       1.0  0.509804  0.135965
9   4         0             0        0             0        1      0.0
0.525843       1.0  0.509804  0.135526,
'pca_train':    id     col_0     col_1     col_2     col_3     col_4
col_5  survived
0   6 -0.568228 -0.135368 -0.228542  0.093113 -0.305830 -0.073679         0
1   8 -0.173794  1.133918  0.309885 -0.488618  0.324486 -0.178287         0
2   9 -0.476815 -0.151025 -0.310885  0.038863  0.152342  0.777571         0
3  10  1.173298  0.616645  0.433740 -0.635511  0.396365  0.200825         1
4  12  1.293204  0.704648 -0.423403 -0.117757  0.028683 -0.374534         1
5  13 -0.648087 -0.168094  0.243070 -0.188860  0.185472 -0.142075         0
6  11 -0.658522 -0.168630  0.187891 -0.099964 -0.189445 -0.061354         0
7   7 -0.645580 -0.166330  0.228935 -0.182779  0.317618 -0.178828         0
8   5  0.985230  0.148005  0.982986  0.640531  0.175075 -0.181205         0
9   4 -0.317333  0.651628  0.800229  0.785804  0.031206
-0.027245         0}
```
6. Visualize the plots on the generated data.
```python
>>> acls.visualize(data=datas['lasso_train'],
target_column='survived',
plot_type = 'all')




```
7. Deploy the generated data to the database.
Note:
  Deployed data can be used across different session using load() api.
```python
>>> acls.deploy(table_name='titanic_deploy')
Data deployed successfully to the table:  titanic_deploy
```
8. Load the deployed data from the database.
a. Create an instance of autodataprep.
```python
>>> adp = AutoDataPrep()
```
b. Load the data from database.
```python
>>> data = adp.load(table_name='titanic_deploy')
>>> data
{'lasso_train':        embarked_0  survived  embarked_1  id  sex_1
embarked_2       age  passenger  sibsp      fare  pclass
sex_0
1               0         0           0  21      0           1  0.490196
0.112360    0.0  0.138523     1.0
1               0         0           0  31      0           1  0.549020
0.020225    0.5  0.315789     1.0
1               0         1           0  33      0           1  0.490196
0.478652    0.5  0.456140     0.5
1               1         1           0  37      0           0  0.019608
0.776404    0.0  0.235381     1.0
1               0         1           0  43      0           1  0.039216
0.065169    0.5  0.486842     0.5
1               0         1           0  47      0           1  0.372549
0.362921    0.5  0.508772     0.5
1               0         1           0  42      0           1  0.725490
0.752809    0.5  0.684211     0.5
1               0         1           0  24      0           1  0.294118
0.731461    0.0  0.403509     0.5
1               0         1           0  19      0           1  0.294118
0.960674    0.0  0.164035     1.0
1               1         1           0  12      0           0  0.647059
0.365169    0.0  0.228070     0.0,
'rfe_train':           r_embarked_1  id  r_sex_0  r_sex_1  r_embarked_2
r_embarked_0     r_age  r_passenger  r_sibsp  r_pclass    r_fare
survived
1                    0  24        1        0             1             0
0.294118     0.731461      0.0       0.5  0.403509
1                    0  30        1        0             1             0
0.529412     0.088764      0.0       1.0  0.218860
1                    0  33        1        0             1             0
0.490196     0.478652      0.5       0.5  0.456140
1                    0  37        1        0             0             1
0.019608     0.776404      0.0       1.0  0.235381
1                    0  42        1        0             1             0
0.725490     0.752809      0.5       0.5  0.684211
1                    0  43        1        0             1             0
0.039216     0.065169      0.5       0.5  0.486842
1                    0  41        0        1             1             0
0.313725     0.317978      0.0       1.0  0.141228
1                    0  25        0        1             1             0
0.568627     0.639326      0.0       1.0  0.137793
1                    0  23        0        1             1             0
0.607843     0.502247      0.0       0.0  0.465789
1                    0  14        1        0             1             0
0.725490     0.180899      0.0       0.5  0.276316,
'pca_train':         col_0     col_1     col_2     col_3     col_4
col_5  survived
id
387  1.207638 -0.662157  0.038470 -0.366528  0.070242 -0.250650
713  0.639786  0.679559  0.340809 -0.197031  0.509808 -0.063763
19   0.637804  0.679945  0.375119 -0.226471  0.547413 -0.059182
753 -0.135545 -1.121384  0.258524 -0.479924 -0.130203  0.365780
0
324  0.731316  0.637457 -0.076783 -0.011871  0.213383 -0.226777
385  0.977002 -0.143439  0.990735  0.659949  0.245793 -0.067303
0
59   0.640228  0.676612  0.383016 -0.243977  0.327815 -0.128798
856 -0.554766  0.130829 -0.172142 -0.008577 -0.327649 -0.235748
0
591 -0.509808  0.147203 -0.345748  0.109265 -0.033826  0.379199
122 -0.402020  0.124281 -0.853962  0.351511  0.124160  0.479015         0}
```
9. Delete the deployed data.
Deletion of data can be partial or complete.
  * Partial delete using fs_method:
```python
>>> adp.delete_data(table_name='titanic_deploy', fs_method='pca')
Removed pca_train table successfully.
```
  * Remove all data (complete):
```python
>>> adp.delete_data(table_name='titanic_deploy')
Removed lasso_train table successfully.
Removed rfe_train table successfully.
Deployed data removed successfully.
```