{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f55b5a83",
   "metadata": {},
   "source": [
    "## Debugging Bullet Detection - Page 27\n",
    "\n",
    "This cell debugs how bullets (•, ◦, etc.) are detected in the PDF on page 27. It extracts raw PDF data and prints:\n",
    "- Block and line indices where bullets appear\n",
    "- The text content after each bullet\n",
    "- X positions of bullet markers\n",
    "\n",
    "This helps verify that the PDF parsing is correctly identifying bullets and their locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e2b607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking bullet detection for page 27:\n",
      "Block 7, Line 0: Found bullet \"•\"\n",
      "Block 8, Line 0: Found bullet \"◦\"\n",
      "Block 9, Line 0: Found bullet \"◦\"\n",
      "Block 10, Line 0: Found bullet \"◦\"\n",
      "Block 13, Line 0: Found bullet \"•\"\n",
      "Block 14, Line 0: Found bullet \"◦\"\n",
      "Block 15, Line 0: Found bullet \"◦\"\n",
      "Block 16, Line 0: Found bullet \"◦\"\n",
      "Block 17, Line 0: Found bullet \"◦\"\n",
      "Block 18, Line 0: Found bullet \"◦\"\n",
      "Block 19, Line 0: Found bullet \"◦\"\n",
      "Block 20, Line 0: Found bullet \"◦\"\n",
      "Block 21, Line 0: Found bullet \"◦\"\n",
      "Block 22, Line 0: Found bullet \"◦\"\n",
      "Block 23, Line 0: Found bullet \"◦\"\n"
     ]
    }
   ],
   "source": [
    "# Debug bullet detection for page 27\n",
    "import fitz\n",
    "\n",
    "doc = fitz.open('Teradata Package for Python User Guide.pdf')\n",
    "page = doc.load_page(26)  # page 27 (0-indexed)\n",
    "data = page.get_text('dict')\n",
    "\n",
    "print(\"Checking bullet detection for page 27:\")\n",
    "for i, block in enumerate(data['blocks']):\n",
    "    if block['type'] == 0:\n",
    "        for j, line in enumerate(block['lines']):\n",
    "            spans = line['spans']\n",
    "            if spans:\n",
    "                line_text = ''\n",
    "                has_bullet_chars = False\n",
    "                first_content_span = None\n",
    "                \n",
    "                for span in spans:\n",
    "                    span_text = span['text'].strip()\n",
    "                    if span_text in ['•', '\\u2022', '◦', '\\u25E6', '*', '-']:\n",
    "                        has_bullet_chars = True\n",
    "                        print(f'Block {i}, Line {j}: Found bullet \"{span_text}\"')\n",
    "                        continue\n",
    "                    if first_content_span is None and span['text'].strip():\n",
    "                        first_content_span = span\n",
    "                    line_text += span['text'] + \" \"\n",
    "                \n",
    "                line_text = line_text.strip()\n",
    "                if line_text and has_bullet_chars:\n",
    "                    print(f'  line_text: \"{line_text}\"')\n",
    "                    print(f'  has_bullet_chars: {has_bullet_chars}')\n",
    "                    if first_content_span:\n",
    "                        x_pos = first_content_span['origin'][0]\n",
    "                        print(f'  first_content_x: {x_pos}')\n",
    "                    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8264c43a",
   "metadata": {},
   "source": [
    "## Debugging Bullet Detection - Page 32\n",
    "\n",
    "Similar to the previous cell, but debugs page 32 instead. This cell analyzes how bullets appear on a different chapter page to verify consistent bullet detection across the PDF.\n",
    "\n",
    "Useful for comparing bullet patterns and X positions across different pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aa355b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking bullet detection for page 32:\n",
      "Block 0, Line 0: Found bullet \"•\"\n",
      "Block 1, Line 0: Found bullet \"•\"\n",
      "Block 2, Line 0: Found bullet \"•\"\n",
      "Block 4, Line 0: Found bullet \"•\"\n",
      "Block 9, Line 0: Found bullet \"•\"\n",
      "Block 13, Line 0: Found bullet \"•\"\n"
     ]
    }
   ],
   "source": [
    "# Debug bullet detection for page 32\n",
    "import fitz\n",
    "\n",
    "doc = fitz.open('Teradata Package for Python User Guide.pdf')\n",
    "page = doc.load_page(31)  # page 32 (0-indexed)\n",
    "data = page.get_text('dict')\n",
    "\n",
    "print(\"Checking bullet detection for page 32:\")\n",
    "for i, block in enumerate(data['blocks']):\n",
    "    if block['type'] == 0:\n",
    "        for j, line in enumerate(block['lines']):\n",
    "            spans = line['spans']\n",
    "            if spans:\n",
    "                line_text = ''\n",
    "                has_bullet_chars = False\n",
    "                first_content_span = None\n",
    "                \n",
    "                for span in spans:\n",
    "                    span_text = span['text'].strip()\n",
    "                    if span_text in ['•', '\\u2022', '◦', '\\u25E6', '*', '-']:\n",
    "                        has_bullet_chars = True\n",
    "                        print(f'Block {i}, Line {j}: Found bullet \"{span_text}\"')\n",
    "                        continue\n",
    "                    if first_content_span is None and span['text'].strip():\n",
    "                        first_content_span = span\n",
    "                    line_text += span['text'] + \" \"\n",
    "                \n",
    "                line_text = line_text.strip()\n",
    "                if line_text and has_bullet_chars:\n",
    "                    print(f'  line_text: \"{line_text}\"')\n",
    "                    print(f'  has_bullet_chars: {has_bullet_chars}')\n",
    "                    if first_content_span:\n",
    "                        x_pos = first_content_span['origin'][0]\n",
    "                        print(f'  first_content_x: {x_pos}')\n",
    "                    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130fdab4",
   "metadata": {},
   "source": [
    "## Import Dependencies\n",
    "\n",
    "Imports the required libraries for PDF parsing and file operations:\n",
    "- `pymupdf` (fitz): For reading and extracting text from PDF files\n",
    "- `os`: For file and directory operations\n",
    "- `re`: For regex pattern matching in text processing\n",
    "- `json`: For working with JSON data (e.g., exporting raw metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018183a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf as fitz\n",
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b1d75",
   "metadata": {},
   "source": [
    "## Configuration: Chapter Map & PDF Metadata\n",
    "\n",
    "Defines the structure of the PDF document:\n",
    "- **CHAPTER_MAP**: A list of tuples containing (chapter_title, start_page, end_page) for each chapter/section in the Teradata Package for Python User Guide\n",
    "- **PDF_FILE**: The path to the PDF file to be parsed\n",
    "\n",
    "The chapter map is used to split the extracted content into separate markdown files per chapter, preserving document structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf3c38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration: Chapter Map & PDF Metadata\n",
    "CHAPTER_MAP = [\n",
    "    (\"Table of Contents\", 3, 6),\n",
    "    (\"Introduction to Teradata Package for Python\", 7, 26),\n",
    "    (\"Installing, Uninstalling, and Upgrading Teradata Package for Python\", 27, 31),\n",
    "    (\"teradataml Components\", 32, 42),\n",
    "    (\"DataFrames Setup and Basics (Sources, Non-Default DB, UAF)\", 43, 60),\n",
    "    (\"DataFrame Manipulation (Core API)\", 61, 164),\n",
    "    (\"DataFrame Metadata, Rotation, Saving, and Export\", 165, 202),\n",
    "    (\"Executing Python Functions Inside Database Engine 20\", 203, 242),\n",
    "    (\"teradataml DataFrame Column\", 243, 279),\n",
    "    (\"teradataml Window Aggregates\", 280, 288),\n",
    "    (\"Context to Teradata Vantage\", 289, 301),\n",
    "    (\"teradataml Options\", 302, 319),\n",
    "    (\"teradataml Utility and General Functions\", 320, 399),\n",
    "    (\"teradataml Open-Source Machine Learning Functions\", 400, 457),\n",
    "    (\"Script Methods (SCRIPT Table Operator)\", 458, 477),\n",
    "    (\"Series (DataFrame Column Sequence)\", 478, 481),\n",
    "    (\"BYOM (Bring Your Own Model) Management\", 482, 519),\n",
    "    (\"Working with Geospatial Data\", 520, 571),\n",
    "    (\"Exploratory Data Analysis (EDA UI)\", 572, 576),\n",
    "    (\"Plotting in teradataml\", 577, 611),\n",
    "    (\"Hyperparameter Tuning in teradataml\", 612, 693),\n",
    "    (\"AutoML Overview and Methods\", 694, 718),\n",
    "    (\"AutoML Examples\", 719, 1108),\n",
    "    (\"AutoDataPrep\", 1109, 1150),\n",
    "    (\"Feature Store in teradataml\", 1151, 1190),\n",
    "    (\"Using Teradata Vantage Analytic Functions with Teradata Package for Python\", 1191, 1235),\n",
    "    (\"Appendix A: Teradata Package for Python Limitations and Considerations\", 1236, 1260),\n",
    "    (\"Appendix B: Using teradataml with Native Object Store\", 1261, 1276),\n",
    "    (\"Appendix C: teradataml Extension with SQLAlchemy\", 1277, 1295),\n",
    "    (\"Appendix D: Data Type Mapping\", 1296, 1297),\n",
    "    (\"Appendix E: Additional Information\", 1298, 1301)\n",
    "]\n",
    "\n",
    "PDF_FILE = \"Teradata Package for Python User Guide.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63df0a2",
   "metadata": {},
   "source": [
    "## Constants: Font Sizes & Constants\n",
    "\n",
    "Defines all constants for PDF parsing:\n",
    "- **Font sizes**: H2 (17.95), H3 (15.96), H4 (11.55) for heading detection\n",
    "- **BODY_TEXT_SIZE**: 10.5 points (standard text)\n",
    "- **CODE_FONT**: 'Consolas' (identifies code blocks)\n",
    "- **BOLD_FLAG**: 16 (bit flag for bold text)\n",
    "- **Bullet character sets**: BLACK_BULLETS (•), WHITE_BULLETS (◦) for nested lists\n",
    "- **Y_MERGE_TOLERANCE**: 5 points (merge lines within this vertical distance)\n",
    "- **APPENDIX_START_INDEX**: 26 (index where appendices begin in chapter map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "130fdab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X-coordinate indentation mapping (generalized across PDF)\n",
    "# Rule: Indentation strictly based on X thresholds (0/2/4/6 spaces)\n",
    "# Rule: Nested levels must have at least +2 more spaces than parent\n",
    "X_INDENT_RANGES = [\n",
    "    (50, 75, 0, None, False),        # Level 0: X ~50-75, 0 spaces, no bullet (main content)\n",
    "    (59, 73, 0, '*', True),          # Level 0 black bullet: X ~59-73, 0 spaces, with bullet •\n",
    "    (72, 85, 2, '*', True),          # Level 1 bullet: X ~72-85, 2 spaces, with bullet • or ◦\n",
    "    (77, 90, 2, None, False),        # Level 1 content: X ~77-90, 2 spaces, no bullet\n",
    "    (85, 115, 4, '*', True),         # Level 2 bullet/content: X ~85-115, 4 spaces, with bullet or no bullet\n",
    "    (111, 130, 4, None, False),      # Level 2 content: X ~111-130, 4 spaces, no bullet\n",
    "    (125, 150, 6, None, False),      # Level 3 content: X ~125-150, 6 spaces, no bullet\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8244e3",
   "metadata": {},
   "source": [
    "## Define PDF Constants\n",
    "\n",
    "Defines all font sizes, styles, and tolerance thresholds used throughout PDF parsing:\n",
    "- **Font sizes**: H2 (17.95pt), H3 (15.96pt), H4 (11.55-13.96pt) for heading detection\n",
    "- **Body text**: 10.5pt standard text size\n",
    "- **Code font**: Consolas (identifies code blocks)\n",
    "- **Bold flag**: 16 (bit flag for bold text)\n",
    "- **Bullet characters**: BLACK_BULLETS (•, •, *) and WHITE_BULLETS (◦) for nested lists\n",
    "- **Tolerances**: Y_MERGE (5pt), Font tolerance (0.01pt)\n",
    "- **APPENDIX_START_INDEX**: Chapter 26 is where appendices begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b75ec509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants: PDF Font Sizes, Styles, and Tolerance Thresholds\n",
    "TOLERANCE = 0.01\n",
    "H2_SIZE_SPECIFIC = 17.954999923706055\n",
    "H3_SIZE_GENERIC = 15.960000038146973\n",
    "H4_SIZE_ARIAL_BLACK = 11.550000190734863\n",
    "H4_SIZE_BOLD_SECONDARY = 13.96500015258789\n",
    "BODY_TEXT_SIZE = 10.5\n",
    "BOLD_FLAG = 16\n",
    "CODE_FONT = 'Consolas'\n",
    "H4_FONT = 'Arial-Black'\n",
    "Y_MERGE_TOLERANCE = 5.0  # Lines within 5 points vertically are part of same row\n",
    "APPENDIX_START_INDEX = 26  # Chapter index where appendices begin\n",
    "\n",
    "# Bullet character detection (consolidated - used in multiple places)\n",
    "BULLET_CHARS = {'•', '\\u2022', '◦', '\\u25E6', '*', '-'}\n",
    "WHITE_BULLETS = {'◦', '\\u25E6'}  # Nested bullets\n",
    "BLACK_BULLETS = {'•', '\\u2022', '*'}  # Main level bullets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac98ff",
   "metadata": {},
   "source": [
    "## X-Coordinate Indentation Mapping\n",
    "\n",
    "Maps X-coordinate positions from the PDF to markdown indentation levels:\n",
    "- **Rule 1**: Indentation is strictly based on X thresholds (0/2/4/6 spaces)\n",
    "- **Rule 2**: Nested levels must have at least +2 more spaces than parent level\n",
    "\n",
    "Each range tuple: `(x_min, x_max, indent_spaces, bullet_marker, is_bullet)`\n",
    "- x_min, x_max: X-coordinate boundaries (in points)\n",
    "- indent_spaces: Number of spaces to apply (0, 2, 4, or 6)\n",
    "- bullet_marker: Expected bullet character (•, ◦, or None)\n",
    "- is_bullet: Whether this range is for bullets\n",
    "\n",
    "This ensures consistent hierarchical indentation across all content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "018183a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indent_from_x(x_pos, bullet_char=None):\n",
    "    \"\"\"\n",
    "    Determine indentation level from X coordinate.\n",
    "    \n",
    "    Indentation is determined STRICTLY by X coordinate thresholds (0/2/4/6 spaces).\n",
    "    Nested levels must have at least +2 more spaces than parent level.\n",
    "    \n",
    "    Args:\n",
    "        x_pos: X coordinate from PDF (PRIMARY source of truth)\n",
    "        bullet_char: bullet character - currently unused, kept for API compatibility\n",
    "    \n",
    "    Returns:\n",
    "        indent_spaces: number of spaces for indentation (0, 2, 4, 6, etc.)\n",
    "    \"\"\"\n",
    "    # Check X coordinate ranges (PRIMARY source of truth)\n",
    "    for x_min, x_max, indent_spaces, bullet_marker, is_bullet in X_INDENT_RANGES:\n",
    "        if x_min <= x_pos < x_max:\n",
    "            return indent_spaces\n",
    "    \n",
    "    # Fallback: if x_pos > 125, estimate based on distance\n",
    "    if x_pos >= 125:\n",
    "        extra_levels = max(0, int((x_pos - 125) / 20))\n",
    "        return 4 + extra_levels * 2\n",
    "    \n",
    "    return 0  # Default: main level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e91d7c",
   "metadata": {},
   "source": [
    "## Utility Function: Get Indentation from X Coordinate\n",
    "\n",
    "**Purpose**: Convert PDF X-coordinate positions to markdown indentation spaces.\n",
    "\n",
    "**Logic**:\n",
    "1. Check X_INDENT_RANGES to find matching range for given x_pos\n",
    "2. Return the indentation_spaces for that range (PRIMARY source of truth)\n",
    "3. For x_pos > 125 (fallback): Estimate based on distance from 125\n",
    "4. Default: Return 0 spaces\n",
    "\n",
    "**Key Design**: Indentation is STRICTLY based on X coordinates, not on bullet characters. This ensures consistent formatting across the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e20682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF Block Processing Functions\n",
    "\n",
    "def merge_table_columns_in_block(block):\n",
    "    \"\"\"\n",
    "    Merge table columns by grouping lines at similar Y coordinates.\n",
    "    Special handling: Do NOT merge bullet characters with content text.\n",
    "    \"\"\"\n",
    "    if not block.get('lines'):\n",
    "        return block['lines']\n",
    "    \n",
    "    # Identify which lines contain ONLY a bullet character\n",
    "    pure_bullet_lines = set()\n",
    "    for line_idx, line in enumerate(block.get('lines', [])):\n",
    "        spans = line.get('spans', [])\n",
    "        if len(spans) == 1 and spans[0]['text'].strip() in BULLET_CHARS:\n",
    "            pure_bullet_lines.add(line_idx)\n",
    "    \n",
    "    # Collect all lines with their Y coordinate, excluding pure bullets from merge\n",
    "    y_groups = {}\n",
    "    for line_idx, line in enumerate(block.get('lines', [])):\n",
    "        if not line.get('spans'):\n",
    "            continue\n",
    "        \n",
    "        # Don't merge pure bullet lines - keep them separate\n",
    "        if line_idx in pure_bullet_lines:\n",
    "            y_groups[len(y_groups)] = [line]  # Each bullet gets its own group\n",
    "            continue\n",
    "        \n",
    "        y_pos = line['bbox'][1]  # Top of bbox\n",
    "        \n",
    "        # Find matching Y group (within tolerance), but only for non-bullet lines\n",
    "        matched_y = None\n",
    "        for existing_y in y_groups:\n",
    "            if isinstance(existing_y, (int, float)) and existing_y < 1000:\n",
    "                if abs(y_pos - existing_y) < Y_MERGE_TOLERANCE:\n",
    "                    matched_y = existing_y\n",
    "                    break\n",
    "        \n",
    "        if matched_y is None:\n",
    "            matched_y = y_pos\n",
    "            y_groups[matched_y] = []\n",
    "        \n",
    "        y_groups[matched_y].append(line)\n",
    "    \n",
    "    # Sort each group by X coordinate and merge spans\n",
    "    merged_lines = []\n",
    "    for key in sorted(y_groups.keys(), key=lambda k: k if isinstance(k, (int, float)) else float('inf')):\n",
    "        lines_in_group = y_groups[key]\n",
    "        \n",
    "        if len(lines_in_group) == 1:\n",
    "            merged_lines.append(lines_in_group[0])\n",
    "        else:\n",
    "            # Multiple lines at same Y - merge them\n",
    "            lines_sorted = sorted(lines_in_group, key=lambda l: l['bbox'][0])\n",
    "            \n",
    "            # Combine spans from all lines, adding spaces between them\n",
    "            merged_spans = []\n",
    "            for line_idx, line in enumerate(lines_sorted):\n",
    "                for span_idx, span in enumerate(line['spans']):\n",
    "                    span_copy = dict(span)\n",
    "                    if line_idx > 0 or span_idx > 0:\n",
    "                        span_copy['text'] = ' ' + span['text']\n",
    "                    merged_spans.append(span_copy)\n",
    "            \n",
    "            # Create merged line\n",
    "            merged_line = {\n",
    "                'spans': merged_spans,\n",
    "                'wmode': lines_sorted[0].get('wmode', 0),\n",
    "                'dir': lines_sorted[0].get('dir', [1.0, 0.0]),\n",
    "                'bbox': [\n",
    "                    lines_sorted[0]['bbox'][0],   # Left of first\n",
    "                    lines_sorted[0]['bbox'][1],   # Top of first\n",
    "                    lines_sorted[-1]['bbox'][2],  # Right of last\n",
    "                    lines_sorted[-1]['bbox'][3],  # Bottom of last\n",
    "                ]\n",
    "            }\n",
    "            merged_lines.append(merged_line)\n",
    "    \n",
    "    return merged_lines\n",
    "\n",
    "def identify_bullet_lines(merged_block_lines):\n",
    "    \"\"\"Identify which lines contain ONLY a bullet character.\"\"\"\n",
    "    bullet_lines = set()\n",
    "    for line_idx, line in enumerate(merged_block_lines):\n",
    "        spans = line.get('spans', [])\n",
    "        if len(spans) == 1 and spans[0]['text'].strip() in BULLET_CHARS:\n",
    "            bullet_lines.add(line_idx)\n",
    "    return bullet_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37d2208",
   "metadata": {},
   "source": [
    "## Line Info Extraction & Helper Functions\n",
    "\n",
    "**extract_line_info()**:\n",
    "- Extracts metadata from each line: text, font size, flags, font name, X position, bullet info\n",
    "- Skips noise: headers, footers, font sizes 24.0 or 8.0\n",
    "- Detects if line had a bullet in previous line and captures bullet character\n",
    "- Returns list of dicts with line info for processing\n",
    "\n",
    "**should_close_code_block()**: Detects headings that should close open code blocks\n",
    "**get_heading_level()**: Determines markdown heading level (2-4) from font characteristics  \n",
    "**is_code_block_text()**: Checks if line is in code font (Consolas) at correct size (10.5pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c5841",
   "metadata": {},
   "source": [
    "## PDF Block Processing Functions\n",
    "\n",
    "**merge_table_columns_in_block()**:\n",
    "- Merges table columns by grouping lines at similar Y coordinates\n",
    "- Preserves bullet characters on separate lines (not merged with content)\n",
    "- Handles multi-column layouts in the PDF\n",
    "\n",
    "**identify_bullet_lines()**:\n",
    "- Identifies which lines contain ONLY a bullet character (•, ◦, etc.)\n",
    "- Returns a set of line indices containing pure bullets\n",
    "- Used to properly handle bullets separately from their content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "095a4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line Info Extraction & Processing\n",
    "\n",
    "def extract_line_info(merged_block_lines, bullet_lines, page_num_1idx):\n",
    "    \"\"\"\n",
    "    Extract and process line metadata from merged block lines.\n",
    "    \n",
    "    Returns:\n",
    "        List of dicts with: text, size, flags, font, is_bold, x_pos, has_bullet, bullet_char, bullet_x_pos\n",
    "    \"\"\"\n",
    "    lines_info = []\n",
    "    \n",
    "    for line_idx, line in enumerate(merged_block_lines):\n",
    "        spans = line.get('spans', [])\n",
    "        if not spans:\n",
    "            continue\n",
    "        \n",
    "        # SKIP pure bullet lines - they only serve to mark the next line\n",
    "        if line_idx in bullet_lines:\n",
    "            continue\n",
    "\n",
    "        first_span = spans[0]\n",
    "        span_size = first_span.get('size', 10)\n",
    "        line_flags = first_span.get('flags', 0)\n",
    "        line_font = first_span.get('font', 'Arial')\n",
    "        x_pos = first_span.get('origin', [0, 0])[0]\n",
    "        \n",
    "        # Skip certain font sizes (headers, noise)\n",
    "        if round(span_size, 1) in [24.0, 8.0]:\n",
    "            continue\n",
    "\n",
    "        line_text = \"\".join([s['text'] for s in spans])\n",
    "        line_text = clean_page_noise(line_text, page_num_1idx).strip()\n",
    "        line_text_clean = line_text.lstrip(' ')\n",
    "        \n",
    "        # Skip chapter/appendix headers and noise\n",
    "        if re.match(r'^(\\d{1,2}|[A-E]):\\s+\\S', line_text_clean):\n",
    "            continue\n",
    "        \n",
    "        if not line_text_clean or re.fullmatch(r'[\\.\\-\\(\\)\\s]*', line_text_clean):\n",
    "            continue\n",
    "        \n",
    "        if line_text_clean.strip() in [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"]:\n",
    "            continue\n",
    "        \n",
    "        is_bold_heading = (line_flags & BOLD_FLAG)\n",
    "        \n",
    "        # Determine if this line had a bullet in previous line\n",
    "        has_bullet_from_previous = False\n",
    "        bullet_char = None\n",
    "        bullet_x_pos = None\n",
    "        if line_idx > 0 and (line_idx - 1) in bullet_lines:\n",
    "            has_bullet_from_previous = True\n",
    "            prev_line = merged_block_lines[line_idx - 1]\n",
    "            if prev_line.get('spans'):\n",
    "                bullet_text = prev_line['spans'][0]['text'].strip()\n",
    "                bullet_char = bullet_text\n",
    "                bullet_x_pos = prev_line['spans'][0].get('origin', [0, 0])[0]\n",
    "        \n",
    "        lines_info.append({\n",
    "            'text': line_text_clean,\n",
    "            'size': span_size,\n",
    "            'flags': line_flags,\n",
    "            'font': line_font,\n",
    "            'is_bold': is_bold_heading,\n",
    "            'x_pos': x_pos,\n",
    "            'has_bullet': has_bullet_from_previous,\n",
    "            'bullet_char': bullet_char,\n",
    "            'bullet_x_pos': bullet_x_pos,\n",
    "        })\n",
    "    \n",
    "    return lines_info\n",
    "\n",
    "def should_close_code_block(line_info):\n",
    "    \"\"\"Determine if we should close any open code block for this line (heading detection).\"\"\"\n",
    "    span_size = line_info['size']\n",
    "    line_flags = line_info['flags']\n",
    "    line_font = line_info['font']\n",
    "    is_bold_heading = line_info['is_bold']\n",
    "    \n",
    "    # Check if this is a heading that should close code blocks\n",
    "    if abs(span_size - H2_SIZE_SPECIFIC) < TOLERANCE and is_bold_heading:\n",
    "        return True\n",
    "    elif abs(span_size - H3_SIZE_GENERIC) < TOLERANCE and is_bold_heading:\n",
    "        return True\n",
    "    elif H4_FONT in line_font and abs(span_size - H4_SIZE_ARIAL_BLACK) < TOLERANCE:\n",
    "        return True\n",
    "    elif round(span_size, 3) == 13.965 and is_bold_heading:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def get_heading_level(line_info):\n",
    "    \"\"\"Get markdown heading level if line is a heading, else None.\"\"\"\n",
    "    span_size = line_info['size']\n",
    "    line_flags = line_info['flags']\n",
    "    line_font = line_info['font']\n",
    "    is_bold_heading = line_info['is_bold']\n",
    "    \n",
    "    if abs(span_size - H2_SIZE_SPECIFIC) < TOLERANCE and is_bold_heading:\n",
    "        return 2\n",
    "    elif abs(span_size - H3_SIZE_GENERIC) < TOLERANCE and is_bold_heading:\n",
    "        return 3\n",
    "    elif H4_FONT in line_font and abs(span_size - H4_SIZE_ARIAL_BLACK) < TOLERANCE:\n",
    "        return 4\n",
    "    elif round(span_size, 3) == 13.965 and is_bold_heading:\n",
    "        return 4\n",
    "    \n",
    "    return None\n",
    "\n",
    "def is_code_block_text(line_info):\n",
    "    \"\"\"Check if line is code text (code font + correct size).\"\"\"\n",
    "    return abs(line_info['size'] - BODY_TEXT_SIZE) < TOLERANCE and line_info['font'] == CODE_FONT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84b78f8",
   "metadata": {},
   "source": [
    "## Core Page Parsing Logic\n",
    "\n",
    "**parse_page_with_metadata()**:\n",
    "- Main function that parses a single PDF page\n",
    "- Handles multi-page code block continuity via state tracking\n",
    "- For each line, determines:\n",
    "  1. Is it a heading? → Close code block, add markdown heading\n",
    "  2. Is it code? → Add to code block with proper formatting\n",
    "  3. Is it regular text? → Apply hierarchical indentation based on X coordinate\n",
    "\n",
    "**Key features**:\n",
    "- Tracks `in_code_block` state across pages\n",
    "- Applies indentation strictly from X_INDENT_RANGES\n",
    "- Handles numbered items and bullet markers\n",
    "- Returns markdown text and updated state for next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a63df0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page_with_metadata(page, page_num_1idx, previous_page_state=None):\n",
    "    \"\"\"\n",
    "    Parse a page with table detection, code vs output distinction, and hierarchical indentation.\n",
    "    \n",
    "    Args:\n",
    "        page: PyMuPDF page object\n",
    "        page_num_1idx: 1-indexed page number\n",
    "        previous_page_state: dict tracking state from previous page\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'markdown': str and 'state': dict for next page\n",
    "    \"\"\"\n",
    "    if previous_page_state is None:\n",
    "        previous_page_state = {'in_code_block': False, 'pending_lines': []}\n",
    "    \n",
    "    data = page.get_text(\"dict\")\n",
    "    blocks = data['blocks']\n",
    "    markdown_lines = []\n",
    "    pending_numbered_item = None\n",
    "    \n",
    "    in_code_block = previous_page_state['in_code_block']\n",
    "    \n",
    "    if previous_page_state['pending_lines']:\n",
    "        markdown_lines.extend(previous_page_state['pending_lines'])\n",
    "        in_code_block = True\n",
    "\n",
    "    # STEP 1: Prepare raw blocks for table detection\n",
    "    all_blocks_with_raw_lines = []\n",
    "    all_merged_blocks = {}\n",
    "    \n",
    "    for block_idx, block in enumerate(blocks):\n",
    "        if block['type'] != 0:\n",
    "            continue\n",
    "        \n",
    "        raw_lines = block.get('lines', [])\n",
    "        all_blocks_with_raw_lines.append((block_idx, raw_lines))\n",
    "        \n",
    "        merged_block_lines = merge_table_columns_in_block(block)\n",
    "        all_merged_blocks[block_idx] = merged_block_lines\n",
    "    \n",
    "    # STEP 2: Detect and convert tables\n",
    "    page_table_markdown, table_line_refs = detect_and_convert_tables_in_page(all_blocks_with_raw_lines, page_num_1idx)\n",
    "    \n",
    "    # Build set of blocks that contain tables (from table_line_refs)\n",
    "    table_blocks_set = set(b_idx for b_idx, _ in table_line_refs)\n",
    "\n",
    "    # STEP 3: Process each block\n",
    "    table_inserted = False\n",
    "    for block_idx, block in enumerate(blocks):\n",
    "        if block['type'] != 0:\n",
    "            continue\n",
    "        \n",
    "        if block_idx not in all_merged_blocks:\n",
    "            continue\n",
    "        \n",
    "        # If this block has table content, insert the table markdown before processing it\n",
    "        if block_idx in table_blocks_set and not table_inserted:\n",
    "            if in_code_block:\n",
    "                markdown_lines.append(\"```\\n\")\n",
    "                in_code_block = False\n",
    "            markdown_lines.append(page_table_markdown)\n",
    "            markdown_lines.append('\\n\\n')\n",
    "            table_inserted = True\n",
    "            # Skip all blocks that contain table content\n",
    "            continue\n",
    "        \n",
    "        # Skip remaining table blocks (but don't re-insert table)\n",
    "        if block_idx in table_blocks_set:\n",
    "            continue\n",
    "        \n",
    "        merged_block_lines = all_merged_blocks[block_idx]\n",
    "        bullet_lines = identify_bullet_lines(merged_block_lines)\n",
    "        lines_info = extract_line_info(merged_block_lines, bullet_lines, page_num_1idx)\n",
    "        \n",
    "        # Process each line in the block\n",
    "        for current in lines_info:\n",
    "            line_text_clean = current['text']\n",
    "            \n",
    "            # Handle numbered items\n",
    "            if re.match(r'^\\d+\\.$', line_text_clean.strip()):\n",
    "                pending_numbered_item = line_text_clean.strip()\n",
    "                continue\n",
    "            \n",
    "            if pending_numbered_item and line_text_clean:\n",
    "                if not line_text_clean.startswith(('###', '####', '```', '*')):\n",
    "                    line_text_clean = f\"{pending_numbered_item} {line_text_clean}\"\n",
    "                    pending_numbered_item = None\n",
    "            \n",
    "            # CONSOLIDATED: Check if heading (closes code blocks automatically)\n",
    "            if should_close_code_block(current):\n",
    "                if in_code_block:\n",
    "                    markdown_lines.append(\"```\\n\")\n",
    "                    in_code_block = False\n",
    "                \n",
    "                heading_level = get_heading_level(current)\n",
    "                heading_marker = '#' * heading_level\n",
    "                markdown_lines.append(f\"{heading_marker} {line_text_clean}\\n\")\n",
    "                continue\n",
    "            \n",
    "            # Code/Output handling\n",
    "            if is_code_block_text(current):\n",
    "                is_code = is_code_line(line_text_clean, current['font'])\n",
    "                \n",
    "                if is_code:\n",
    "                    # Start or continue python code block with REPL prompt\n",
    "                    if not in_code_block:\n",
    "                        markdown_lines.append(\"```python\\n\")\n",
    "                        in_code_block = True\n",
    "                    markdown_lines.append(line_text_clean + \"\\n\")\n",
    "                else:\n",
    "                    # This is output (code font text after >>> lines)\n",
    "                    if in_code_block:\n",
    "                        markdown_lines.append(line_text_clean + \"\\n\")\n",
    "                    else:\n",
    "                        # Orphaned code-font text - treat as regular code\n",
    "                        if not in_code_block:\n",
    "                            markdown_lines.append(\"```python\\n\")\n",
    "                            in_code_block = True\n",
    "                        markdown_lines.append(line_text_clean + \"\\n\")\n",
    "            \n",
    "            else:\n",
    "                # Regular body text (non-code-font) - apply hierarchical indentation\n",
    "                if in_code_block:\n",
    "                    markdown_lines.append(\"```\\n\")\n",
    "                    in_code_block = False\n",
    "                \n",
    "                # Determine indentation from X coordinate (strictly based on X_INDENT_RANGES)\n",
    "                indent_x_pos = current['bullet_x_pos'] if current['has_bullet'] and current['bullet_x_pos'] is not None else current['x_pos']\n",
    "                indent_spaces = get_indent_from_x(indent_x_pos, current['bullet_char'])\n",
    "                \n",
    "                indent_str = ' ' * indent_spaces\n",
    "                \n",
    "                # Apply bullet marker if present\n",
    "                if current['has_bullet']:\n",
    "                    markdown_lines.append(f\"{indent_str}* {line_text_clean}\\n\")\n",
    "                else:\n",
    "                    markdown_lines.append(f\"{indent_str}{line_text_clean}\\n\")\n",
    "    \n",
    "    # Determine final state for next page\n",
    "    final_state = {\n",
    "        'in_code_block': in_code_block,\n",
    "        'pending_lines': []\n",
    "    }\n",
    "    \n",
    "    final_text = \"\".join(markdown_lines)\n",
    "    final_text = re.sub(r'\\n{3,}', '\\n\\n', final_text)\n",
    "    \n",
    "    return {\n",
    "        'markdown': final_text.strip(),\n",
    "        'state': final_state\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92bd012",
   "metadata": {},
   "source": [
    "## Bullet Conversion & File Export Functions\n",
    "\n",
    "**convert_bullets_in_text()**:\n",
    "- Post-processing step to convert old bullet characters to markdown format\n",
    "- Replaces • and ◦ with * (markdown bullet syntax)\n",
    "- Preserves indentation from X coordinate parsing\n",
    "- Ensures proper spacing for nested bullets\n",
    "\n",
    "**export_raw_page_metadata()**:\n",
    "- Debugging utility that exports raw PDF metadata for a specific page as JSON\n",
    "- Helps diagnose PDF parsing issues\n",
    "- Outputs: raw text dict structure from PyMuPDF with all font/position info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7c4a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bullet Conversion & File Export Functions\n",
    "\n",
    "def convert_bullets_in_text(text):\n",
    "    \"\"\"\n",
    "    Convert old bullet characters (• and ◦) to markdown format (* with proper indentation).\n",
    "    \n",
    "    This is a post-processing step for any bullets that weren't converted during parsing.\n",
    "    \"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    converted_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        # Replace • with * (main bullet)\n",
    "        if '•' in line or '\\u2022' in line:\n",
    "            match = re.match(r'^(\\s*)([•\\u2022])\\s*(.*)', line)\n",
    "            if match:\n",
    "                spaces, bullet, content = match.groups()\n",
    "                converted_lines.append(f\"{spaces}* {content}\")\n",
    "            else:\n",
    "                line = line.replace('•', '*').replace('\\u2022', '*')\n",
    "                converted_lines.append(line)\n",
    "        \n",
    "        # Replace ◦ with * (nested bullet) - ensure 4 spaces\n",
    "        elif '◦' in line or '\\u25E6' in line:\n",
    "            match = re.match(r'^(\\s*)([◦\\u25E6])\\s*(.*)', line)\n",
    "            if match:\n",
    "                spaces, bullet, content = match.groups()\n",
    "                if len(spaces) < 4:\n",
    "                    spaces = '    '  # Force 4 spaces for nested\n",
    "                converted_lines.append(f\"{spaces}* {content}\")\n",
    "            else:\n",
    "                line = line.replace('◦', '*').replace('\\u25E6', '*')\n",
    "                converted_lines.append(line)\n",
    "        else:\n",
    "            converted_lines.append(line)\n",
    "    \n",
    "    return '\\n'.join(converted_lines)\n",
    "\n",
    "def export_raw_page_metadata(pdf_path, page_num_1idx, output_filename):\n",
    "    \"\"\"Export raw PDF metadata for a specific page (for debugging).\"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        if 0 < page_num_1idx <= doc.page_count:\n",
    "            page_num_0idx = page_num_1idx - 1\n",
    "            page = doc.load_page(page_num_0idx)\n",
    "            data = page.get_text(\"dict\")\n",
    "            with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(json.dumps(data, indent=4))\n",
    "            print(f\"✨ Successfully exported raw metadata for page {page_num_1idx} to '{output_filename}'.\")\n",
    "        else:\n",
    "            print(f\"Error: Page number {page_num_1idx} is out of bounds.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: PDF file not found at '{pdf_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during metadata export: {e}\")\n",
    "    finally:\n",
    "        if 'doc' in locals() and doc:\n",
    "            doc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7074e156",
   "metadata": {},
   "source": [
    "## Extract Table Rows from PDF Blocks\n",
    "\n",
    "**extract_table_rows_from_blocks()**:\n",
    "- Extracts table rows from a range of PDF blocks\n",
    "- Groups PDF spans by Y coordinate (same Y = same row, within 5px tolerance)\n",
    "- For each row, groups cells by X coordinate (with 10px rounding)\n",
    "- Identifies all unique column positions across the table\n",
    "- Pads all rows to same column count with empty strings\n",
    "- Returns: List of rows, each row is a list of cell strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e0857d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_rows_from_blocks(all_blocks_with_raw_lines, table_start, table_end):\n",
    "    \"\"\"\n",
    "    Extract table rows by:\n",
    "    1. Collecting all lines from all blocks with their Y coordinates\n",
    "    2. Grouping lines by Y coordinate (same Y = same row)\n",
    "    3. For each row, extracting cells by X position\n",
    "    4. Ensuring all rows have consistent column count (padding with empty strings)\n",
    "    \n",
    "    Args:\n",
    "        all_blocks_with_raw_lines: List of (block_idx, raw_lines) tuples\n",
    "        table_start, table_end: Block range\n",
    "    \n",
    "    Returns: List of rows, each row is a list of cells\n",
    "    \"\"\"\n",
    "    block_dict = dict(all_blocks_with_raw_lines)\n",
    "    \n",
    "    # Step 1: Collect all lines with their Y and X coordinates\n",
    "    all_lines_with_coords = []\n",
    "    for block_idx in range(table_start, table_end + 1):\n",
    "        if block_idx not in block_dict:\n",
    "            continue\n",
    "        \n",
    "        for line in block_dict[block_idx]:\n",
    "            if not line.get('spans'):\n",
    "                continue\n",
    "            \n",
    "            # Each span in a line can be at different X\n",
    "            for span in line.get('spans', []):\n",
    "                y = span.get('origin', [0, 0])[1]\n",
    "                x = span.get('origin', [0, 0])[0]\n",
    "                text = span.get('text', '')\n",
    "                all_lines_with_coords.append((y, x, text))\n",
    "    \n",
    "    # Step 2: Group by Y coordinate (within 5px tolerance)\n",
    "    y_groups = {}\n",
    "    for y, x, text in sorted(all_lines_with_coords, key=lambda item: item[0]):\n",
    "        # Find matching Y group\n",
    "        matched_y = None\n",
    "        for existing_y in y_groups:\n",
    "            if abs(y - existing_y) < 5:  # Y tolerance\n",
    "                matched_y = existing_y\n",
    "                break\n",
    "        \n",
    "        if matched_y is None:\n",
    "            matched_y = y\n",
    "            y_groups[matched_y] = []\n",
    "        \n",
    "        y_groups[matched_y].append((x, text))\n",
    "    \n",
    "    # Step 3: Identify all unique X column positions across entire table\n",
    "    all_x_positions = set()\n",
    "    for y_key in y_groups.keys():\n",
    "        cells_list = y_groups[y_key]\n",
    "        for x, text in cells_list:\n",
    "            x_key = round(x / 10) * 10  # Round X to nearest 10px\n",
    "            all_x_positions.add(x_key)\n",
    "    \n",
    "    sorted_x_positions = sorted(all_x_positions)\n",
    "    \n",
    "    # Step 4: Build rows by organizing cells by X position\n",
    "    rows = []\n",
    "    for y_key in sorted(y_groups.keys()):\n",
    "        cells_list = y_groups[y_key]\n",
    "        \n",
    "        # Group by X position (cells in same X column)\n",
    "        x_groups = {}\n",
    "        for x, text in cells_list:\n",
    "            x_key = round(x / 10) * 10  # Round X to nearest 10px\n",
    "            if x_key not in x_groups:\n",
    "                x_groups[x_key] = []\n",
    "            x_groups[x_key].append(text)\n",
    "        \n",
    "        # Create row with cells for ALL column positions (fill missing with empty strings)\n",
    "        row = []\n",
    "        for x_key in sorted_x_positions:\n",
    "            if x_key in x_groups:\n",
    "                cell_text = \"\".join(x_groups[x_key]).strip()\n",
    "            else:\n",
    "                cell_text = \"\"\n",
    "            row.append(cell_text)\n",
    "        \n",
    "        if any(row):  # Only add if row has at least one non-empty cell\n",
    "            rows.append(row)\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61a9c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_table_blocks_in_page(all_blocks_with_raw_lines):\n",
    "    \"\"\"\n",
    "    Detect table blocks by identifying aligned X-coordinates across multiple rows.\n",
    "    \n",
    "    A table is detected when:\n",
    "    1. There are 2+ X positions (multi-column layout)\n",
    "    2. Font size is ~10.028pt (table text size)\n",
    "    3. X gap between columns >= 100px (distinct columns, not just formatting)\n",
    "    4. Footer text is EXCLUDED via regex pattern, not by size\n",
    "    \n",
    "    Footer pattern: \"Package for Python User Guide, Release xx.xx\"\n",
    "    This ensures robust footer filtering across future PDF updates.\n",
    "    \n",
    "    Args:\n",
    "        all_blocks_with_raw_lines: List of (block_idx, raw_lines) tuples\n",
    "    \n",
    "    Returns:\n",
    "        List of (table_start_block, table_end_block) tuples for detected tables\n",
    "    \"\"\"\n",
    "    # Regex to detect footer/header text (version-agnostic)\n",
    "    FOOTER_PATTERN = re.compile(r'Package for Python User Guide,?\\s+Release\\s+[\\d.]+', re.IGNORECASE)\n",
    "    TABLE_FONT_SIZE = 10.028  # Table text font size (with tolerance)\n",
    "    FONT_SIZE_TOLERANCE = 0.05\n",
    "    MIN_X_GAP = 100  # Minimum gap between columns\n",
    "    \n",
    "    # Step 1: Find blocks that contain table-like text\n",
    "    table_candidate_blocks = []\n",
    "    \n",
    "    for block_idx, raw_lines in all_blocks_with_raw_lines:\n",
    "        if not raw_lines:\n",
    "            continue\n",
    "        \n",
    "        # Check if this block has table-like characteristics\n",
    "        has_table_font = False\n",
    "        x_positions = set()\n",
    "        \n",
    "        for line in raw_lines:\n",
    "            for span in line.get('spans', []):\n",
    "                # Filter out footer text via regex\n",
    "                span_text = span.get('text', '')\n",
    "                if FOOTER_PATTERN.search(span_text):\n",
    "                    continue  # Skip footer lines\n",
    "                \n",
    "                # Check font size\n",
    "                span_size = span.get('size', 0)\n",
    "                if abs(span_size - TABLE_FONT_SIZE) < FONT_SIZE_TOLERANCE:\n",
    "                    has_table_font = True\n",
    "                    x = span.get('origin', [0, 0])[0]\n",
    "                    x_key = round(x / 10) * 10  # Round X to nearest 10px\n",
    "                    x_positions.add(x_key)\n",
    "        \n",
    "        # Determine if this is a table block\n",
    "        if has_table_font and len(x_positions) >= 2:\n",
    "            # Check if columns are distinct (gap >= MIN_X_GAP)\n",
    "            sorted_x = sorted(x_positions)\n",
    "            is_table = False\n",
    "            for i in range(len(sorted_x) - 1):\n",
    "                if sorted_x[i+1] - sorted_x[i] >= MIN_X_GAP:\n",
    "                    is_table = True\n",
    "                    break\n",
    "            \n",
    "            if is_table:\n",
    "                table_candidate_blocks.append(block_idx)\n",
    "    \n",
    "    # Step 2: Group consecutive table blocks into ranges\n",
    "    if not table_candidate_blocks:\n",
    "        return []\n",
    "    \n",
    "    table_ranges = []\n",
    "    range_start = table_candidate_blocks[0]\n",
    "    range_end = table_candidate_blocks[0]\n",
    "    \n",
    "    for block_idx in table_candidate_blocks[1:]:\n",
    "        if block_idx == range_end + 1:\n",
    "            range_end = block_idx\n",
    "        else:\n",
    "            table_ranges.append((range_start, range_end))\n",
    "            range_start = block_idx\n",
    "            range_end = block_idx\n",
    "    \n",
    "    table_ranges.append((range_start, range_end))\n",
    "    return table_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa2dbed",
   "metadata": {},
   "source": [
    "## Format Markdown Table & Convert Tables\n",
    "\n",
    "**format_markdown_table()**:\n",
    "- Converts extracted table rows to markdown format (| separated columns)\n",
    "- Deduplicates consecutive identical rows (header repetition in PDFs)\n",
    "- Pads all rows to same column count with empty strings\n",
    "- Returns properly formatted markdown table\n",
    "\n",
    "**detect_and_convert_tables_in_page()**:\n",
    "- Master function that orchestrates table detection and conversion\n",
    "- Detects table block ranges, extracts rows, converts to markdown\n",
    "- Combines multiple tables with newlines between them\n",
    "- Returns: (markdown_table_str, set of block_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3ca536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_markdown_table(rows):\n",
    "    \"\"\"\n",
    "    Convert extracted table rows to markdown table format.\n",
    "    \n",
    "    Handles:\n",
    "    1. Deduplication of consecutive identical rows (header repetition)\n",
    "    2. Proper column alignment\n",
    "    3. Markdown pipe separators\n",
    "    \n",
    "    Args:\n",
    "        rows: List of lists, each inner list is a row of cells\n",
    "    \n",
    "    Returns:\n",
    "        Formatted markdown table string\n",
    "    \"\"\"\n",
    "    if not rows or all(len(row) == 0 for row in rows):\n",
    "        return \"\"\n",
    "    \n",
    "    def normalize_row(row):\n",
    "        \"\"\"Normalize row for deduplication: lowercase, collapse whitespace.\"\"\"\n",
    "        normalized_cells = [re.sub(r'\\s+', ' ', cell.strip().lower()) for cell in row]\n",
    "        return normalized_cells\n",
    "    \n",
    "    # Deduplicate consecutive identical rows (header rows appearing multiple times)\n",
    "    deduplicated = []\n",
    "    prev_normalized = None\n",
    "    \n",
    "    for row in rows:\n",
    "        curr_normalized = normalize_row(row)\n",
    "        if curr_normalized != prev_normalized:\n",
    "            deduplicated.append(row)\n",
    "            prev_normalized = curr_normalized\n",
    "    \n",
    "    rows = deduplicated\n",
    "    if not rows:\n",
    "        return \"\"\n",
    "    \n",
    "    # Determine column count\n",
    "    num_cols = max(len(row) for row in rows) if rows else 0\n",
    "    if num_cols == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    # Ensure all rows have same column count\n",
    "    for row in rows:\n",
    "        while len(row) < num_cols:\n",
    "            row.append(\"\")\n",
    "    \n",
    "    # Build markdown table\n",
    "    markdown_lines = []\n",
    "    \n",
    "    # Header row\n",
    "    markdown_lines.append(\"| \" + \" | \".join(rows[0]) + \" |\")\n",
    "    \n",
    "    # Separator row\n",
    "    separator = \"| \" + \" | \".join([\"-\" * max(1, len(cell)) for cell in rows[0]]) + \" |\"\n",
    "    markdown_lines.append(separator)\n",
    "    \n",
    "    # Data rows\n",
    "    for row in rows[1:]:\n",
    "        markdown_lines.append(\"| \" + \" | \".join(row) + \" |\")\n",
    "    \n",
    "    return \"\\n\".join(markdown_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b96e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_convert_tables_in_page(all_blocks_with_raw_lines, page_num_1idx):\n",
    "    \"\"\"\n",
    "    Master function: Detect tables on page and convert to markdown format.\n",
    "    \n",
    "    Args:\n",
    "        all_blocks_with_raw_lines: List of (block_idx, raw_lines) tuples\n",
    "        page_num_1idx: Page number (1-indexed, for debugging)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (markdown_table_str, set of (block_idx, line_idx) table references)\n",
    "    \"\"\"\n",
    "    # Detect table block ranges\n",
    "    table_ranges = detect_table_blocks_in_page(all_blocks_with_raw_lines)\n",
    "    \n",
    "    if not table_ranges:\n",
    "        return \"\", set()\n",
    "    \n",
    "    # Extract and convert each table range\n",
    "    all_table_markdown = []\n",
    "    all_table_refs = set()\n",
    "    \n",
    "    for table_start, table_end in table_ranges:\n",
    "        # Extract rows from this table range\n",
    "        rows = extract_table_rows_from_blocks(all_blocks_with_raw_lines, table_start, table_end)\n",
    "        \n",
    "        # Convert to markdown\n",
    "        table_md = format_markdown_table(rows)\n",
    "        \n",
    "        if table_md:\n",
    "            all_table_markdown.append(table_md)\n",
    "            # Track which blocks contain this table\n",
    "            for block_idx in range(table_start, table_end + 1):\n",
    "                all_table_refs.add((block_idx, 0))  # Store block reference\n",
    "    \n",
    "    # Combine all tables with newlines between them\n",
    "    combined_markdown = \"\\n\\n\".join(all_table_markdown) if all_table_markdown else \"\"\n",
    "    \n",
    "    return combined_markdown, all_table_refs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c714d5c",
   "metadata": {},
   "source": [
    "## Table Detection and Markdown Conversion\n",
    "\n",
    "**detect_table_blocks()**:\n",
    "- Identifies table blocks by detecting aligned X-coordinates across multiple rows\n",
    "- A table is detected when 2+ rows share similar X-coordinate boundaries\n",
    "- Returns list of table blocks and their column boundaries\n",
    "\n",
    "**extract_table_rows()**:\n",
    "- Extracts rows from a detected table block\n",
    "- Consolidates multi-line cells using proper line breaks\n",
    "- Returns structured row data with column values\n",
    "\n",
    "**is_table_header_row()**:\n",
    "- Detects table headers by checking for bold font and specific font sizes\n",
    "- Headers are typically 10pt Arial-Bold in this PDF\n",
    "\n",
    "**format_markdown_table()**:\n",
    "- Converts extracted table data to markdown table format\n",
    "- Handles multi-line cells with `<br>` tags for proper markdown rendering\n",
    "- Ensures clean, readable output for GitHub Copilot\n",
    "\n",
    "**detect_and_convert_tables()**:\n",
    "- Master function that processes all blocks in a page\n",
    "- Detects tables, extracts rows, formats as markdown\n",
    "- Integrates seamlessly with existing parsing pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0a024eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Extraction & Chapter Processing\n",
    "\n",
    "def extract_and_split_by_chapter(pdf_path, chapter_map, output_dir=\"teradataml_user_guide\"):\n",
    "    \"\"\"\n",
    "    Extract chapters from PDF and split into markdown files.\n",
    "    Handles multi-page code block continuity within chapters.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to PDF file\n",
    "        chapter_map: List of (title, start_page, end_page) tuples\n",
    "        output_dir: Output directory for markdown files\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        total_pages = doc.page_count\n",
    "\n",
    "        for idx, (title, start_page_1idx, end_page_1idx) in enumerate(chapter_map):\n",
    "            start_page_0idx = start_page_1idx - 1\n",
    "            end_page_0idx = end_page_1idx - 1\n",
    "            \n",
    "            if start_page_0idx < 0 or end_page_0idx >= total_pages:\n",
    "                continue\n",
    "\n",
    "            chapter_text = [f\"# {title}\\n\\n\"] \n",
    "            page_state = {'in_code_block': False, 'pending_lines': []}\n",
    "            \n",
    "            # Process each page in chapter\n",
    "            for page_num_0idx in range(start_page_0idx, end_page_0idx + 1):\n",
    "                page = doc.load_page(page_num_0idx)\n",
    "                result = parse_page_with_metadata(page, page_num_0idx + 1, page_state)\n",
    "                \n",
    "                markdown_text = result['markdown']\n",
    "                page_state = result['state']\n",
    "                \n",
    "                chapter_text.append(markdown_text)\n",
    "                chapter_text.append('\\n')\n",
    "            \n",
    "            # Close any open code block at end of chapter\n",
    "            if page_state['in_code_block']:\n",
    "                chapter_text.append(\"```\\n\")\n",
    "            \n",
    "            # Post-process: convert any remaining old bullet characters\n",
    "            final_text = \"\".join(chapter_text).strip()\n",
    "            final_text = convert_bullets_in_text(final_text)\n",
    "            \n",
    "            # Determine output filename with prefix\n",
    "            if idx == 0:\n",
    "                prefix = \"00\"\n",
    "            elif idx < APPENDIX_START_INDEX:\n",
    "                prefix = f\"{idx:02d}\"\n",
    "            else:\n",
    "                appendix_index = idx - APPENDIX_START_INDEX\n",
    "                prefix = chr(ord('A') + appendix_index)\n",
    "            \n",
    "            safe_title = sanitize_title(title)\n",
    "            output_filename = os.path.join(output_dir, f\"{prefix}_{safe_title}.md\")\n",
    "            \n",
    "            # Write to file\n",
    "            with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(final_text)\n",
    "            print(f\"✓ Generated {output_filename}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during extraction: {e}\")\n",
    "    finally:\n",
    "        if 'doc' in locals() and doc:\n",
    "            doc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d59ed",
   "metadata": {},
   "source": [
    "## Helper Functions: Title Sanitization & Noise Removal\n",
    "\n",
    "**sanitize_title()**:\n",
    "- Cleans chapter titles for safe filenames\n",
    "- Removes chapter/appendix prefixes\n",
    "- Removes special characters, keeps word chars + parentheses/brackets\n",
    "- Replaces spaces with underscores\n",
    "- Example: \"Chapter 1: DataFrames Setup\" → \"DataFrames_Setup\"\n",
    "\n",
    "**clean_page_noise()**:\n",
    "- Strips header/footer noise from extracted text\n",
    "- Removes file name header (\"Teradata® Package for Python User Guide...\")\n",
    "- Removes page numbers and chapter title fragments\n",
    "- Cleans up multiple newlines and non-breaking spaces\n",
    "- Post-processing to ensure clean, readable markdown\n",
    "\n",
    "**is_code_line()**:\n",
    "- Determines if a line is actual code (vs output)\n",
    "- Checks if line is in Consolas font and starts with >>> or ...\n",
    "- Used to distinguish between code prompts and output in code blocks\n",
    "- Returns True only if entire line is code (REPL prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0ccdd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_title(title):\n",
    "    \"\"\"\n",
    "    Clean chapter titles for use in filenames.\n",
    "    \n",
    "    Steps:\n",
    "    1. Remove leading chapter/appendix prefix (e.g., \"Chapter 1:\", \"Appendix A:\")\n",
    "    2. Remove special characters (keep only word chars, spaces, parentheses, brackets, hyphens)\n",
    "    3. Replace spaces/hyphens with underscores\n",
    "    \n",
    "    Args:\n",
    "        title: Raw chapter title from PDF\n",
    "    \n",
    "    Returns:\n",
    "        Sanitized title safe for filenames\n",
    "    \n",
    "    Example:\n",
    "        \"Chapter 1: DataFrames Setup and Basics\" → \"DataFrames_Setup_and_Basics\"\n",
    "    \"\"\"\n",
    "    title = re.sub(r'^(Chapter\\s\\d{1,2}|Appendix\\s[A-E]):\\s*', '', title, flags=re.IGNORECASE)\n",
    "    title = re.sub(r'[^\\w\\s()\\[\\]-]', '', title)\n",
    "    title = re.sub(r'[\\s-]+', '_', title).strip('_')\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68e1631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_page_noise(text, page_number):\n",
    "    \"\"\"\n",
    "    Strip header/footer noise and non-breaking spaces from extracted text.\n",
    "    \n",
    "    Removes:\n",
    "    1. File header (\"Teradata® Package for Python User Guide, Release 20.00\")\n",
    "    2. Page numbers in headers/footers\n",
    "    3. Chapter title fragments used in headers\n",
    "    4. Multiple consecutive newlines\n",
    "    5. Non-breaking spaces (U+00A0)\n",
    "    \n",
    "    Args:\n",
    "        text: Raw extracted text from PDF page\n",
    "        page_number: Current page number (1-indexed, used to find page number in headers)\n",
    "    \n",
    "    Returns:\n",
    "        Clean text with noise removed\n",
    "    \"\"\"\n",
    "    FILE_NAME_REGEX = re.escape(\"Teradata® Package for Python User Guide, Release 20.00\")\n",
    "    text = re.sub(FILE_NAME_REGEX, '', text)\n",
    "    page_num_regex = re.escape(str(page_number))\n",
    "    text = re.sub(rf'\\s*{page_num_regex}\\s*', '\\n', text)\n",
    "    chapter_title_fragments = [\n",
    "        r'Context to Teradata Vantage', r'teradataml DataFrame Column', r'Executing Python Functions Inside Database',\n",
    "        r'DataFrames for Tables and Views', r'teradataml Window Aggregates', r'teradataml Options',\n",
    "        r'teradataml Utility and General Functions', r'Engine 20', r'Table and Views',\n",
    "        r'Installing, Uninstalling, and Upgrading Teradata Package for Python'\n",
    "    ]\n",
    "    fragment_pattern = r'|'.join(re.escape(f) for f in chapter_title_fragments)\n",
    "    noise_regex = re.compile(\n",
    "        r'^\\s*(\\d{1,2}:\\s*.*(?:' + fragment_pattern + r').*|.*(?:' + fragment_pattern + r')\\s*\\d{1,2}\\s*)\\s*$', \n",
    "        flags=re.IGNORECASE | re.MULTILINE\n",
    "    )\n",
    "    text = re.sub(noise_regex, '', text).strip()\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text).strip()\n",
    "    text = text.replace('\\u00a0', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65c19066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_code_line(line_text_clean, line_font):\n",
    "    \"\"\"\n",
    "    Determine if a line is actual Python code (vs output from code execution).\n",
    "    \n",
    "    A line is considered code if:\n",
    "    1. It's in the CODE_FONT (Consolas)\n",
    "    2. It starts with Python REPL prompt (>>> or ...)\n",
    "    \n",
    "    Used to distinguish between:\n",
    "    - Code: \">>> result = df.head()\"\n",
    "    - Output: \"Name  Age  Score\"\n",
    "    \n",
    "    Args:\n",
    "        line_text_clean: The text content of the line (already trimmed)\n",
    "        line_font: Font name extracted from PDF (e.g., 'Consolas', 'Arial')\n",
    "    \n",
    "    Returns:\n",
    "        True if line is code (has REPL prompt), False if it's output\n",
    "    \"\"\"\n",
    "    if line_font != CODE_FONT:\n",
    "        return False\n",
    "    return line_text_clean.startswith(('>>>', '...'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f14fcb",
   "metadata": {},
   "source": [
    "## Main Extraction & Chapter Processing\n",
    "\n",
    "**extract_and_split_by_chapter()**:\n",
    "- Main orchestration function that processes the entire PDF\n",
    "- For each chapter in CHAPTER_MAP:\n",
    "  1. Initialize page state tracker\n",
    "  2. Parse each page using parse_page_with_metadata()\n",
    "  3. Track code block state across pages for continuity\n",
    "  4. Close any open code blocks at chapter end\n",
    "  5. Post-process to convert remaining bullet characters\n",
    "  6. Generate output filename with prefix (00, 01-25 for chapters, A-E for appendices)\n",
    "  7. Write markdown to file\n",
    "\n",
    "**Outputs**: One markdown file per chapter in `teradataml_user_guide/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caa2a4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Generated teradataml_user_guide/00_Table_of_Contents.md\n",
      "✓ Generated teradataml_user_guide/01_Introduction_to_Teradata_Package_for_Python.md\n",
      "✓ Generated teradataml_user_guide/02_Installing_Uninstalling_and_Upgrading_Teradata_Package_for_Python.md\n",
      "✓ Generated teradataml_user_guide/03_teradataml_Components.md\n",
      "✓ Generated teradataml_user_guide/04_DataFrames_Setup_and_Basics_(Sources_Non_Default_DB_UAF).md\n",
      "✓ Generated teradataml_user_guide/03_teradataml_Components.md\n",
      "✓ Generated teradataml_user_guide/04_DataFrames_Setup_and_Basics_(Sources_Non_Default_DB_UAF).md\n",
      "✓ Generated teradataml_user_guide/05_DataFrame_Manipulation_(Core_API).md\n",
      "✓ Generated teradataml_user_guide/05_DataFrame_Manipulation_(Core_API).md\n",
      "✓ Generated teradataml_user_guide/06_DataFrame_Metadata_Rotation_Saving_and_Export.md\n",
      "✓ Generated teradataml_user_guide/06_DataFrame_Metadata_Rotation_Saving_and_Export.md\n",
      "✓ Generated teradataml_user_guide/07_Executing_Python_Functions_Inside_Database_Engine_20.md\n",
      "✓ Generated teradataml_user_guide/07_Executing_Python_Functions_Inside_Database_Engine_20.md\n",
      "✓ Generated teradataml_user_guide/08_teradataml_DataFrame_Column.md\n",
      "✓ Generated teradataml_user_guide/09_teradataml_Window_Aggregates.md\n",
      "✓ Generated teradataml_user_guide/10_Context_to_Teradata_Vantage.md\n",
      "✓ Generated teradataml_user_guide/08_teradataml_DataFrame_Column.md\n",
      "✓ Generated teradataml_user_guide/09_teradataml_Window_Aggregates.md\n",
      "✓ Generated teradataml_user_guide/10_Context_to_Teradata_Vantage.md\n",
      "✓ Generated teradataml_user_guide/11_teradataml_Options.md\n",
      "✓ Generated teradataml_user_guide/11_teradataml_Options.md\n",
      "✓ Generated teradataml_user_guide/12_teradataml_Utility_and_General_Functions.md\n",
      "✓ Generated teradataml_user_guide/12_teradataml_Utility_and_General_Functions.md\n",
      "✓ Generated teradataml_user_guide/13_teradataml_Open_Source_Machine_Learning_Functions.md\n",
      "✓ Generated teradataml_user_guide/13_teradataml_Open_Source_Machine_Learning_Functions.md\n",
      "✓ Generated teradataml_user_guide/14_Script_Methods_(SCRIPT_Table_Operator).md\n",
      "✓ Generated teradataml_user_guide/15_Series_(DataFrame_Column_Sequence).md\n",
      "✓ Generated teradataml_user_guide/14_Script_Methods_(SCRIPT_Table_Operator).md\n",
      "✓ Generated teradataml_user_guide/15_Series_(DataFrame_Column_Sequence).md\n",
      "✓ Generated teradataml_user_guide/16_BYOM_(Bring_Your_Own_Model)_Management.md\n",
      "✓ Generated teradataml_user_guide/16_BYOM_(Bring_Your_Own_Model)_Management.md\n",
      "✓ Generated teradataml_user_guide/17_Working_with_Geospatial_Data.md\n",
      "✓ Generated teradataml_user_guide/17_Working_with_Geospatial_Data.md\n",
      "✓ Generated teradataml_user_guide/18_Exploratory_Data_Analysis_(EDA_UI).md\n",
      "✓ Generated teradataml_user_guide/18_Exploratory_Data_Analysis_(EDA_UI).md\n",
      "✓ Generated teradataml_user_guide/19_Plotting_in_teradataml.md\n",
      "✓ Generated teradataml_user_guide/19_Plotting_in_teradataml.md\n",
      "✓ Generated teradataml_user_guide/20_Hyperparameter_Tuning_in_teradataml.md\n",
      "✓ Generated teradataml_user_guide/20_Hyperparameter_Tuning_in_teradataml.md\n",
      "✓ Generated teradataml_user_guide/21_AutoML_Overview_and_Methods.md\n",
      "✓ Generated teradataml_user_guide/21_AutoML_Overview_and_Methods.md\n",
      "✓ Generated teradataml_user_guide/22_AutoML_Examples.md\n",
      "✓ Generated teradataml_user_guide/22_AutoML_Examples.md\n",
      "✓ Generated teradataml_user_guide/23_AutoDataPrep.md\n",
      "✓ Generated teradataml_user_guide/23_AutoDataPrep.md\n",
      "✓ Generated teradataml_user_guide/24_Feature_Store_in_teradataml.md\n",
      "✓ Generated teradataml_user_guide/24_Feature_Store_in_teradataml.md\n",
      "✓ Generated teradataml_user_guide/25_Using_Teradata_Vantage_Analytic_Functions_with_Teradata_Package_for_Python.md\n",
      "✓ Generated teradataml_user_guide/25_Using_Teradata_Vantage_Analytic_Functions_with_Teradata_Package_for_Python.md\n",
      "✓ Generated teradataml_user_guide/A_Teradata_Package_for_Python_Limitations_and_Considerations.md\n",
      "✓ Generated teradataml_user_guide/B_Using_teradataml_with_Native_Object_Store.md\n",
      "✓ Generated teradataml_user_guide/A_Teradata_Package_for_Python_Limitations_and_Considerations.md\n",
      "✓ Generated teradataml_user_guide/B_Using_teradataml_with_Native_Object_Store.md\n",
      "✓ Generated teradataml_user_guide/C_teradataml_Extension_with_SQLAlchemy.md\n",
      "✓ Generated teradataml_user_guide/D_Data_Type_Mapping.md\n",
      "✓ Generated teradataml_user_guide/E_Additional_Information.md\n",
      "\n",
      "✅ Extraction complete with all bullet characters converted to markdown!\n",
      "✓ Generated teradataml_user_guide/C_teradataml_Extension_with_SQLAlchemy.md\n",
      "✓ Generated teradataml_user_guide/D_Data_Type_Mapping.md\n",
      "✓ Generated teradataml_user_guide/E_Additional_Information.md\n",
      "\n",
      "✅ Extraction complete with all bullet characters converted to markdown!\n"
     ]
    }
   ],
   "source": [
    "# Execution: Extract and Process PDF\n",
    "\n",
    "if os.path.exists(PDF_FILE):\n",
    "    extract_and_split_by_chapter(PDF_FILE, CHAPTER_MAP)\n",
    "    print(\"\\n✅ Extraction complete with all bullet characters converted to markdown!\")\n",
    "else:\n",
    "    print(f\"Error: PDF file not found at '{PDF_FILE}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a4cf39",
   "metadata": {},
   "source": [
    "## Execute PDF Extraction Workflow\n",
    "\n",
    "Runs the main extraction orchestration:\n",
    "1. Checks if PDF file exists at PDF_FILE path\n",
    "2. Calls extract_and_split_by_chapter() to parse entire PDF\n",
    "3. Processes all chapters per CHAPTER_MAP\n",
    "4. Generates markdown files in teradataml_user_guide/ directory\n",
    "\n",
    "**Output**: Confirmation message + list of generated chapter files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "549821b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Consolidate Markdown Tables: Merge split tables across pages\n",
    "\n",
    "Algorithm:\n",
    "- Find table blocks (header line followed by separator |---|...)\n",
    "- For consecutive table blocks, if headers match and columns align, merge them\n",
    "- For single contiguous blocks with repeated headers inside, remove the duplicate headers\n",
    "- Only processes markdown files (post-extraction consolidation)\n",
    "\"\"\"\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "TABLE_HEADER_RE = re.compile(r\"^\\s*\\|.*\\|\\s*$\")\n",
    "SEPARATOR_RE = re.compile(r\"^\\s*\\|(?:\\s*-+\\s*\\|)+\\s*$\")\n",
    "\n",
    "def normalize_row(row):\n",
    "    # Normalize header row for comparison: lowercase, collapse whitespace\n",
    "    return re.sub(r\"\\s+\", \" \", row.strip().lower())\n",
    "\n",
    "def find_table_blocks(lines):\n",
    "    blocks = []  # list of (start_idx, end_idx)\n",
    "    i = 0\n",
    "    n = len(lines)\n",
    "    while i < n:\n",
    "        if TABLE_HEADER_RE.match(lines[i]):\n",
    "            # candidate header, check next line is separator\n",
    "            if i + 1 < n and SEPARATOR_RE.match(lines[i+1]):\n",
    "                start = i\n",
    "                j = i + 2\n",
    "                # extend until a non-table line\n",
    "                while j < n and lines[j].strip().startswith('|'):\n",
    "                    j += 1\n",
    "                end = j - 1\n",
    "                blocks.append((start, end))\n",
    "                i = j\n",
    "                continue\n",
    "        i += 1\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a0d5e3",
   "metadata": {},
   "source": [
    "## Deduplicate & Merge Table Blocks\n",
    "\n",
    "**dedupe_duplicate_headers_within_block()**:\n",
    "- Removes repeated header+separator pairs within a single table block\n",
    "- Happens when PDF has headers that repeat due to page breaks\n",
    "- Returns: (deduplicated_lines, changed_flag)\n",
    "\n",
    "**merge_blocks_in_lines()**:\n",
    "- Merges consecutive table blocks with matching headers and column count\n",
    "- Only merges if intermediate lines are blank (no content between tables)\n",
    "- Iteratively processes until no more merges are possible\n",
    "- Returns: True if any merges occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a98355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedupe_duplicate_headers_within_block(block_lines):\n",
    "    \"\"\"\n",
    "    Given a list of lines that form a contiguous markdown table block,\n",
    "    remove any repeated header+separator pairs that appear later in the block.\n",
    "    \"\"\"\n",
    "    if len(block_lines) < 3:\n",
    "        return block_lines, False\n",
    "\n",
    "    header = normalize_row(block_lines[0])\n",
    "    changed = False\n",
    "    i = 2  # start after header and separator\n",
    "    out_lines = block_lines[:2]\n",
    "    while i < len(block_lines):\n",
    "        line = block_lines[i]\n",
    "        # if this line looks like the header and next is a separator -> skip both\n",
    "        next_line = block_lines[i+1] if i+1 < len(block_lines) else ''\n",
    "        if normalize_row(line) == header and SEPARATOR_RE.match(next_line):\n",
    "            # skip header+separator\n",
    "            changed = True\n",
    "            i += 2\n",
    "            # continue without adding these lines\n",
    "            continue\n",
    "        out_lines.append(line)\n",
    "        i += 1\n",
    "\n",
    "    return out_lines, changed\n",
    "\n",
    "def merge_blocks_in_lines(lines):\n",
    "    changed = False\n",
    "    blocks = find_table_blocks(lines)\n",
    "    # iterate and attempt merges\n",
    "    i = 1\n",
    "    while i < len(blocks):\n",
    "        prev_start, prev_end = blocks[i-1]\n",
    "        cur_start, cur_end = blocks[i]\n",
    "        # check intermediate lines between prev_end and cur_start are blank\n",
    "        inter = ''.join(lines[prev_end+1:cur_start]).strip()\n",
    "        if inter != '':\n",
    "            i += 1\n",
    "            continue\n",
    "        # get header rows\n",
    "        header_prev = normalize_row(lines[prev_start])\n",
    "        header_cur = normalize_row(lines[cur_start])\n",
    "        if header_prev != header_cur:\n",
    "            i += 1\n",
    "            continue\n",
    "        # count columns by splitting header on | and ignoring empty edges\n",
    "        def col_count(row):\n",
    "            parts = [p.strip() for p in row.strip().strip('|').split('|')]\n",
    "            return len(parts)\n",
    "        if col_count(lines[prev_start]) != col_count(lines[cur_start]):\n",
    "            i += 1\n",
    "            continue\n",
    "        # perform merge: append data rows from cur (skip header and separator) to prev\n",
    "        data_rows = lines[cur_start+2:cur_end+1]\n",
    "        # remove trailing empty lines from prev_end if any\n",
    "        insert_pos = prev_end + 1\n",
    "        # insert data rows\n",
    "        lines[insert_pos:insert_pos] = data_rows\n",
    "        # now remove the original cur block (which shifted forward by len(data_rows))\n",
    "        del lines[insert_pos+len(data_rows): insert_pos+len(data_rows) + (cur_end - cur_start +1)]\n",
    "        changed = True\n",
    "        # rebuild blocks and restart scanning\n",
    "        blocks = find_table_blocks(lines)\n",
    "        i = 1\n",
    "    return changed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3423d",
   "metadata": {},
   "source": [
    "## Process Files & Execute Consolidation\n",
    "\n",
    "**process_file()**:\n",
    "- Main consolidation processor for a single markdown file\n",
    "- Merges consecutive table blocks first\n",
    "- Then dedupes headers within each block\n",
    "- Writes changes back to file if any modifications occurred\n",
    "- Returns: True if file was modified\n",
    "\n",
    "**consolidate_md_tables()**:\n",
    "- Entry point: processes all markdown files in a directory\n",
    "- Calls process_file() on each markdown file\n",
    "- Tracks and reports total files changed\n",
    "- Returns: count of files that were modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bee32ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(path: Path):\n",
    "    text = path.read_text(encoding='utf-8')\n",
    "    lines = text.splitlines(keepends=True)\n",
    "    changed = merge_blocks_in_lines(lines)\n",
    "    # Also dedupe repeated header+separator pairs that may appear inside a single block\n",
    "    blocks = find_table_blocks(lines)\n",
    "    for start, end in reversed(blocks):\n",
    "        block_lines = lines[start:end+1]\n",
    "        new_block, block_changed = dedupe_duplicate_headers_within_block(block_lines)\n",
    "        if block_changed:\n",
    "            lines[start:end+1] = new_block\n",
    "            changed = True\n",
    "    if changed:\n",
    "        path.write_text(''.join(lines), encoding='utf-8')\n",
    "    return changed\n",
    "\n",
    "def consolidate_md_tables(dir_path):\n",
    "    \"\"\"Process all markdown files in directory to consolidate split tables.\"\"\"\n",
    "    target = Path(dir_path)\n",
    "    files = list(target.rglob('*.md')) if target.is_dir() else [target] if target.is_file() else []\n",
    "    \n",
    "    total_changed = 0\n",
    "    for f in files:\n",
    "        changed = process_file(f)\n",
    "        if changed:\n",
    "            print(f'✓ Merged tables in: {f.name}')\n",
    "            total_changed += 1\n",
    "    \n",
    "    return total_changed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd28a3d7",
   "metadata": {},
   "source": [
    "## Exporting raw PDF Metadata for debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db23303a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨ Successfully exported raw metadata for page 1119 to 'page_1119_raw_metadata_debug.txt'.\n"
     ]
    }
   ],
   "source": [
    "export_raw_page_metadata(PDF_FILE, 1119, \"page_1119_raw_metadata_debug.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311gcopilot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
