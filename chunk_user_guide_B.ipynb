{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8ff023",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Consolidate Markdown Tables: Merge split tables across pages\n",
    "\n",
    "Algorithm:\n",
    "- Find table blocks (header line followed by separator |---|...)\n",
    "- For consecutive table blocks, if headers match and columns align, merge them\n",
    "- For single contiguous blocks with repeated headers inside, remove the duplicate headers\n",
    "- Only processes markdown files (post-extraction consolidation)\n",
    "\"\"\"\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "TABLE_HEADER_RE = re.compile(r\"^\\s*\\|.*\\|\\s*$\")\n",
    "SEPARATOR_RE = re.compile(r\"^\\s*\\|(?:\\s*-+\\s*\\|)+\\s*$\")\n",
    "\n",
    "def normalize_row(row):\n",
    "    # Normalize header row for comparison: lowercase, collapse whitespace\n",
    "    return re.sub(r\"\\s+\", \" \", row.strip().lower())\n",
    "\n",
    "def find_table_blocks(lines):\n",
    "    blocks = []  # list of (start_idx, end_idx)\n",
    "    i = 0\n",
    "    n = len(lines)\n",
    "    while i < n:\n",
    "        if TABLE_HEADER_RE.match(lines[i]):\n",
    "            # candidate header, check next line is separator\n",
    "            if i + 1 < n and SEPARATOR_RE.match(lines[i+1]):\n",
    "                start = i\n",
    "                j = i + 2\n",
    "                # extend until a non-table line\n",
    "                while j < n and lines[j].strip().startswith('|'):\n",
    "                    j += 1\n",
    "                end = j - 1\n",
    "                blocks.append((start, end))\n",
    "                i = j\n",
    "                continue\n",
    "        i += 1\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a0d5e3",
   "metadata": {},
   "source": [
    "## Deduplicate & Merge Table Blocks\n",
    "\n",
    "**dedupe_duplicate_headers_within_block()**:\n",
    "- Removes repeated header+separator pairs within a single table block\n",
    "- Happens when PDF has headers that repeat due to page breaks\n",
    "- Returns: (deduplicated_lines, changed_flag)\n",
    "\n",
    "**merge_blocks_in_lines()**:\n",
    "- Merges consecutive table blocks with matching headers and column count\n",
    "- Only merges if intermediate lines are blank (no content between tables)\n",
    "- Iteratively processes until no more merges are possible\n",
    "- Returns: True if any merges occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a98355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedupe_duplicate_headers_within_block(block_lines):\n",
    "    \"\"\"\n",
    "    Given a list of lines that form a contiguous markdown table block,\n",
    "    remove any repeated header+separator pairs that appear later in the block.\n",
    "    \"\"\"\n",
    "    if len(block_lines) < 3:\n",
    "        return block_lines, False\n",
    "\n",
    "    header = normalize_row(block_lines[0])\n",
    "    changed = False\n",
    "    i = 2  # start after header and separator\n",
    "    out_lines = block_lines[:2]\n",
    "    while i < len(block_lines):\n",
    "        line = block_lines[i]\n",
    "        # if this line looks like the header and next is a separator -> skip both\n",
    "        next_line = block_lines[i+1] if i+1 < len(block_lines) else ''\n",
    "        if normalize_row(line) == header and SEPARATOR_RE.match(next_line):\n",
    "            # skip header+separator\n",
    "            changed = True\n",
    "            i += 2\n",
    "            # continue without adding these lines\n",
    "            continue\n",
    "        out_lines.append(line)\n",
    "        i += 1\n",
    "\n",
    "    return out_lines, changed\n",
    "\n",
    "def merge_blocks_in_lines(lines):\n",
    "    changed = False\n",
    "    blocks = find_table_blocks(lines)\n",
    "    # iterate and attempt merges\n",
    "    i = 1\n",
    "    while i < len(blocks):\n",
    "        prev_start, prev_end = blocks[i-1]\n",
    "        cur_start, cur_end = blocks[i]\n",
    "        # check intermediate lines between prev_end and cur_start are blank\n",
    "        inter = ''.join(lines[prev_end+1:cur_start]).strip()\n",
    "        if inter != '':\n",
    "            i += 1\n",
    "            continue\n",
    "        # get header rows\n",
    "        header_prev = normalize_row(lines[prev_start])\n",
    "        header_cur = normalize_row(lines[cur_start])\n",
    "        if header_prev != header_cur:\n",
    "            i += 1\n",
    "            continue\n",
    "        # count columns by splitting header on | and ignoring empty edges\n",
    "        def col_count(row):\n",
    "            parts = [p.strip() for p in row.strip().strip('|').split('|')]\n",
    "            return len(parts)\n",
    "        if col_count(lines[prev_start]) != col_count(lines[cur_start]):\n",
    "            i += 1\n",
    "            continue\n",
    "        # perform merge: append data rows from cur (skip header and separator) to prev\n",
    "        data_rows = lines[cur_start+2:cur_end+1]\n",
    "        # remove trailing empty lines from prev_end if any\n",
    "        insert_pos = prev_end + 1\n",
    "        # insert data rows\n",
    "        lines[insert_pos:insert_pos] = data_rows\n",
    "        # now remove the original cur block (which shifted forward by len(data_rows))\n",
    "        del lines[insert_pos+len(data_rows): insert_pos+len(data_rows) + (cur_end - cur_start +1)]\n",
    "        changed = True\n",
    "        # rebuild blocks and restart scanning\n",
    "        blocks = find_table_blocks(lines)\n",
    "        i = 1\n",
    "    return changed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3423d",
   "metadata": {},
   "source": [
    "## Process Files & Execute Consolidation\n",
    "\n",
    "**process_file()**:\n",
    "- Main consolidation processor for a single markdown file\n",
    "- Merges consecutive table blocks first\n",
    "- Then dedupes headers within each block\n",
    "- Writes changes back to file if any modifications occurred\n",
    "- Returns: True if file was modified\n",
    "\n",
    "**consolidate_md_tables()**:\n",
    "- Entry point: processes all markdown files in a directory\n",
    "- Calls process_file() on each markdown file\n",
    "- Tracks and reports total files changed\n",
    "- Returns: count of files that were modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee32ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(path: Path):\n",
    "    text = path.read_text(encoding='utf-8')\n",
    "    lines = text.splitlines(keepends=True)\n",
    "    changed = merge_blocks_in_lines(lines)\n",
    "    # Also dedupe repeated header+separator pairs that may appear inside a single block\n",
    "    blocks = find_table_blocks(lines)\n",
    "    for start, end in reversed(blocks):\n",
    "        block_lines = lines[start:end+1]\n",
    "        new_block, block_changed = dedupe_duplicate_headers_within_block(block_lines)\n",
    "        if block_changed:\n",
    "            lines[start:end+1] = new_block\n",
    "            changed = True\n",
    "    if changed:\n",
    "        path.write_text(''.join(lines), encoding='utf-8')\n",
    "    return changed\n",
    "\n",
    "def consolidate_md_tables(dir_path):\n",
    "    \"\"\"Process all markdown files in directory to consolidate split tables.\"\"\"\n",
    "    target = Path(dir_path)\n",
    "    files = list(target.rglob('*.md')) if target.is_dir() else [target] if target.is_file() else []\n",
    "    \n",
    "    total_changed = 0\n",
    "    for f in files:\n",
    "        changed = process_file(f)\n",
    "        if changed:\n",
    "            print(f'âœ“ Merged tables in: {f.name}')\n",
    "            total_changed += 1\n",
    "    \n",
    "    return total_changed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d238edc",
   "metadata": {},
   "source": [
    "## Execute Table Consolidation\n",
    "\n",
    "Run the consolidation process on all generated markdown files to merge split tables and remove duplicate headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9c8b5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning 36 markdown files in teradataml_user_guide...\n",
      "\n",
      "ðŸ“Š 01_Introduction_to_Teradata_Package_for_Python.md:\n",
      "   Tables found at lines: [99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157]\n",
      "   Total table lines: 59\n",
      "\n",
      "ðŸ“Š 04_DataFrames_Setup_and_Basics_(Sources_Non_Default_DB_UAF).md:\n",
      "   Tables found at lines: [30, 31, 32, 33, 34, 35, 36, 37, 38]\n",
      "   Total table lines: 9\n",
      "\n",
      "ðŸ“Š 05_DataFrame_Manipulation_(Core_API).md:\n",
      "   Tables found at lines: [407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293]\n",
      "   Total table lines: 97\n",
      "\n",
      "ðŸ“Š 07_Executing_Python_Functions_Inside_Database_Engine_20.md:\n",
      "   Tables found at lines: [28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 165, 166, 167, 168, 169, 170, 171, 330, 331, 332, 333, 334, 339, 340, 341, 348, 349, 350, 351, 352, 353, 354, 355, 360, 361, 362, 363, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892]\n",
      "   Total table lines: 102\n",
      "\n",
      "ðŸ“Š 08_teradataml_DataFrame_Column.md:\n",
      "   Tables found at lines: [877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1105, 1106, 1107, 1108, 1109, 1110, 1116, 1117, 1118, 1119, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145]\n",
      "   Total table lines: 225\n",
      "\n",
      "ðŸ“Š 09_teradataml_Window_Aggregates.md:\n",
      "   Tables found at lines: [245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279]\n",
      "   Total table lines: 35\n",
      "\n",
      "ðŸ“Š 12_teradataml_Utility_and_General_Functions.md:\n",
      "   Tables found at lines: [74, 75, 76, 77, 78, 79, 80, 81, 82, 333, 334, 335, 336, 337, 338, 339, 340, 341]\n",
      "   Total table lines: 18\n",
      "\n",
      "ðŸ“Š 16_BYOM_(Bring_Your_Own_Model)_Management.md:\n",
      "   Tables found at lines: [7, 8, 9, 10, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695]\n",
      "   Total table lines: 29\n",
      "\n",
      "ðŸ“Š 17_Working_with_Geospatial_Data.md:\n",
      "   Tables found at lines: [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 570, 571, 572, 573, 574, 577, 578, 579, 580, 581, 582, 583, 584, 587, 588, 589, 590, 591, 592, 593, 594, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 695, 696, 697, 698, 699, 700, 701, 702, 703, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 720, 721, 722, 723, 724, 726, 727, 728, 729, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 748, 749, 750, 751, 752, 753, 938, 939, 940, 941, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 970, 971, 972, 973, 974, 977, 978, 979, 980, 981, 982, 983, 984, 987, 988, 989, 990, 991, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1061, 1062, 1063, 1064, 1065, 1068, 1069, 1070, 1071, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094]\n",
      "   Total table lines: 340\n",
      "\n",
      "ðŸ“Š 24_Feature_Store_in_teradataml.md:\n",
      "   Tables found at lines: [46, 47, 48, 49, 50, 51]\n",
      "   Total table lines: 6\n",
      "\n",
      "ðŸ“Š 25_Additional_Information.md:\n",
      "   Tables found at lines: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "   Total table lines: 19\n",
      "\n",
      "ðŸ“Š 25_Data_Type_Mapping.md:\n",
      "   Tables found at lines: [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
      "   Total table lines: 37\n",
      "\n",
      "ðŸ“Š 25_Teradata_Package_for_Python_Limitations_and_Considerations.md:\n",
      "   Tables found at lines: [151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 320, 321, 322, 323, 324]\n",
      "   Total table lines: 15\n",
      "\n",
      "ðŸ“Š 25_teradataml_Extension_with_SQLAlchemy.md:\n",
      "   Tables found at lines: [143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 260, 261, 262, 263, 264, 268, 269, 270, 271, 272, 273, 274, 275, 276, 288, 289, 290, 291, 292, 293, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462]\n",
      "   Total table lines: 158\n",
      "\n",
      "ðŸ“Š A_Teradata_Package_for_Python_Limitations_and_Considerations.md:\n",
      "   Tables found at lines: [151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 320, 321, 322, 323, 324]\n",
      "   Total table lines: 15\n",
      "\n",
      "ðŸ“Š C_teradataml_Extension_with_SQLAlchemy.md:\n",
      "   Tables found at lines: [143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 292, 293, 294, 295, 296, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482]\n",
      "   Total table lines: 138\n",
      "\n",
      "ðŸ“Š D_Data_Type_Mapping.md:\n",
      "   Tables found at lines: [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
      "   Total table lines: 37\n",
      "\n",
      "ðŸ“Š E_Additional_Information.md:\n",
      "   Tables found at lines: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "   Total table lines: 19\n",
      "\n",
      "\n",
      "Summary: 18 out of 36 files contain tables\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def find_tables_in_markdown_files(directory):\n",
    "    \"\"\"\n",
    "    Scan all markdown files in a directory and report where tables are found.\n",
    "    \"\"\"\n",
    "    table_pattern = re.compile(r\"^\\s*\\|\\s*.*\\|\\s*$\", re.MULTILINE)\n",
    "    \n",
    "    md_files = [f for f in os.listdir(directory) if f.endswith(\".md\")]\n",
    "    md_files.sort()\n",
    "    \n",
    "    print(f\"Scanning {len(md_files)} markdown files in {directory}...\\n\")\n",
    "    \n",
    "    files_with_tables = []\n",
    "    \n",
    "    for filename in md_files:\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        try:\n",
    "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            lines = content.split(\"\\n\")\n",
    "            table_lines = []\n",
    "            \n",
    "            for i, line in enumerate(lines, 1):\n",
    "                if table_pattern.match(line):\n",
    "                    table_lines.append(i)\n",
    "            \n",
    "            if table_lines:\n",
    "                files_with_tables.append((filename, table_lines))\n",
    "                print(f\"ðŸ“Š {filename}:\")\n",
    "                print(f\"   Tables found at lines: {table_lines}\")\n",
    "                print(f\"   Total table lines: {len(table_lines)}\")\n",
    "                print()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error reading {filename}: {e}\")\n",
    "    \n",
    "    print(f\"\\nSummary: {len(files_with_tables)} out of {len(md_files)} files contain tables\")\n",
    "    \n",
    "    return files_with_tables\n",
    "\n",
    "# Scan the teradataml_user_guide directory\n",
    "table_files = find_tables_in_markdown_files(\"teradataml_user_guide\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55c78e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Merged tables in: 01_Introduction_to_Teradata_Package_for_Python.md\n",
      "âœ“ Merged tables in: 04_DataFrames_Setup_and_Basics_(Sources_Non_Default_DB_UAF).md\n",
      "âœ“ Merged tables in: 05_DataFrame_Manipulation_(Core_API).md\n",
      "âœ“ Merged tables in: 07_Executing_Python_Functions_Inside_Database_Engine_20.md\n",
      "âœ“ Merged tables in: 08_teradataml_DataFrame_Column.md\n",
      "âœ“ Merged tables in: 09_teradataml_Window_Aggregates.md\n",
      "âœ“ Merged tables in: 16_BYOM_(Bring_Your_Own_Model)_Management.md\n",
      "âœ“ Merged tables in: 17_Working_with_Geospatial_Data.md\n",
      "âœ“ Merged tables in: 25_Additional_Information.md\n",
      "âœ“ Merged tables in: 25_Data_Type_Mapping.md\n",
      "âœ“ Merged tables in: 25_teradataml_Extension_with_SQLAlchemy.md\n",
      "âœ“ Merged tables in: 25_Teradata_Package_for_Python_Limitations_and_Considerations.md\n",
      "âœ“ Merged tables in: A_Teradata_Package_for_Python_Limitations_and_Considerations.md\n",
      "âœ“ Merged tables in: C_teradataml_Extension_with_SQLAlchemy.md\n",
      "âœ“ Merged tables in: D_Data_Type_Mapping.md\n",
      "âœ“ Merged tables in: E_Additional_Information.md\n",
      "\n",
      "âœ… Consolidation complete. 16 file(s) changed.\n"
     ]
    }
   ],
   "source": [
    "# Run consolidation on generated markdown\n",
    "total_changed = consolidate_md_tables(\"teradataml_user_guide\")\n",
    "print(f'\\nâœ… Consolidation complete. {total_changed} file(s) changed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29959dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311gcopilot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
